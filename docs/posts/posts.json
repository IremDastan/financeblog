[
  {
    "path": "posts/2022-11-03-eventstudy/",
    "title": "Event Study: How do CBRT policy rate announcements affect stocks?",
    "description": "We are gonna event study methodology this study.",
    "author": [
      {
        "name": "Irem Dastan",
        "url": {}
      }
    ],
    "date": "2022-11-03",
    "categories": [
      "Event study",
      "Policy rate",
      "Macroeconomic announcement"
    ],
    "contents": "\r\nIn this study, the effect of the interest rate decisions announced by\r\nthe Central Bank of the Republic of Turkey (CBRT) on stocks on the\r\nstocks in BIST30 was investigated. To put it in more detail, the\r\nreaction of the Central Bank of the Republic of Turkey to the asset\r\nprices before and after the interest (increase, decrease and constant)\r\nannouncements has been examined. The data set between the years\r\n2015-2022 was used. Daily data set for stocks (BIST30) and monthly data\r\nset for CBRT interest rate announcements are used. In addition, case\r\nstudy was used as a method.\r\n\r\n\r\nlibrary(readxl);library(tidyverse);library(openxlsx);\r\nlibrary(data.table);library(zoo);library(kableExtra)\r\n\r\n\r\n\r\nData are from Bloomberg\r\n\r\n\r\n# Daily stock data import\r\nDaily_Stock <- read_excel(\"data.xlsx\",\r\nsheet = \"daily_stock\") %>%\r\nmutate(ASELS = na.locf(ASELS)) %>%\r\npivot_longer(!DATE, names_to = \"Ticker\",values_to = \"LastPriceTicker\")\r\n# Daily index data import\r\nDaily_Index <- read_excel(\"data.xlsx\",\r\nsheet = \"daily_index\")\r\n\r\n\r\n\r\nMETHODOLOGY\r\nThe case study methodology of Brown and Warner (1985) was used in\r\nthis study. The research subject of the study is how the CBRT interest\r\nrate announcements will affect the stocks listed in the BIST30 index.\r\nThe data set includes the closing prices of BIST 30 assets between\r\nJanuary 2, 2015 and May 30, 2022. Within this date range, there are 66\r\ninterest announcements by the CBRT.\r\nIn the study, the estimation window is designed as [-252, -10] and\r\nthe event window as [-10, 10]. Within the scope of the study, abnormal\r\nreturns (AR) and cumulative abnormal returns (CAR) were calculated and\r\nt-statistics was applied.\r\nCalculating the Return\r\n\r\n\r\n# Calculating the Stock Return\r\n\r\nDaily_Stock <- Daily_Stock %>%\r\n  arrange(Ticker) %>%\r\n  group_by(Ticker) %>%\r\n  mutate(lagLastPriceTicker=shift(LastPriceTicker, 1, type= \"lag\"),\r\n         perReturnTicker= (LastPriceTicker-lagLastPriceTicker)/lagLastPriceTicker,\r\n         logReturnTicker= log(LastPriceTicker/lagLastPriceTicker)) %>%\r\n  ungroup()\r\n\r\n\r\nggplot(Daily_Stock, aes(x=DATE, y=perReturnTicker, group= Ticker)) +\r\n  geom_line(color=\"#80d7cc\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\", hjust = 0.5)) +\r\n  geom_hline(yintercept = 0) +\r\n  ggtitle(\"Stocks Return\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Calculating the BIST100-Index Return\r\n\r\nDaily_Index <- Daily_Index %>%\r\n  mutate(lagXU100=shift(XU100, 1, type= \"lag\"),\r\n         perReturnXU100= (XU100-lagXU100)/lagXU100,\r\n         logReturnXU100= log(XU100/lagXU100))\r\n\r\n\r\nggplot(Daily_Index, aes(x=DATE, y=perReturnXU100)) +\r\n  geom_line(color=\"orange\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\", hjust = 0.5)) +\r\n  geom_hline(yintercept = 0) +\r\n  ggtitle(\"XU100 Index Return\")\r\n\r\n\r\n\r\n\r\nCalculating the Abnormal\r\nReturn\r\nHere abnormal return is calculated. The abnormal return is the\r\ndifference between the realized return and the expected return on a\r\nsecurity. The abnormal return formula is as follows.\r\n\\(Ai,t = Ri,t − Rm,t\\)\r\nwhere;\r\nRm,t is the BIST100 index for day \\(t\\), \\(Ri,t\\) is also the percentage return for\r\nsecurity \\(i\\) at day \\(t\\) and finally \\(Ai,t\\) is defined as the excess return for\r\nsecurity \\(i\\) at day \\(t\\).\r\n\r\n\r\n# Calculating the Abnormal Return\r\n\r\ndf_daily <- Daily_Stock %>%\r\n  left_join(Daily_Index, by = \"DATE\") %>%\r\n  mutate(AR = perReturnTicker - perReturnXU100,\r\n         DATE = as.Date(DATE)) %>%\r\n  arrange(Ticker,DATE)\r\n\r\n\r\n\r\n\r\n\r\n# Importing the event days\r\n\r\ndf_EventDay <- read_excel(\"data.xlsx\", sheet = \"announcement\") %>%\r\n  arrange(DATE) %>%\r\n  mutate(\r\n    \"DIFF\" = lag(lead(RATE) - RATE),\r\n    \"DECISION\" = case_when(\r\n      DIFF == 0 ~ \"CONSTANT\",\r\n      DIFF > 0 ~ \"INCREASED\",\r\n      DIFF < 0 ~ \"DECREASED\"\r\n      )\r\n    ) %>%\r\n  na.omit()\r\n\r\nticker <- df_daily %>% select(Ticker) %>% distinct() %>% pull(Ticker)\r\neventday <- df_EventDay %>% pull(DATE) %>% as.Date()\r\n\r\n\r\n\r\nEstimation and Event Window\r\nHere we calculate the estimation period and event period for each\r\nstock. Our Estimation window is (-252, -10) and our event window is\r\n(-10, 10).\r\n\r\n\r\nknitr::include_graphics(\"event_est_window.png\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n# -10 & 10\r\n\r\nbefore <- 10\r\nafter <- 10\r\n\r\nmaster <- data.frame()\r\n\r\nfor(i in 1:length(ticker)) {\r\n  \r\n  for (j in 1:length(eventday)) {\r\n    finalFilter <- df_daily %>%\r\n      arrange(Ticker) %>%\r\n      group_by(Ticker) %>%\r\n      mutate(ID = row_number()) %>%\r\n      filter(Ticker == ticker[i])\r\n    id <- finalFilter %>%\r\n      filter(DATE == as.Date(eventday[j])) %>%\r\n      pull(ID)\r\n    \r\n    final <- finalFilter %>%\r\n      filter(ID >= (id - before) & ID <= (id + after)) %>%\r\n      mutate(DATE = as.Date(DATE)) %>%\r\n      dplyr::select(DATE, Ticker, AR) %>%\r\n      mutate(EventDay = eventday[j])\r\n    master <- master %>% bind_rows(final)\r\n    }\r\n  }\r\n\r\nmaster2 <- master %>%\r\n  group_by(Ticker,EventDay) %>%\r\n  mutate(\r\n    day = seq(before*-1,after,1)\r\n    ) %>%\r\n  ungroup() %>%\r\n  left_join(df_EventDay[,c(1,4)], by = \"DATE\") %>%\r\n  group_by(EventDay) %>%\r\n  mutate(RN = cur_group_id()) %>%\r\n  ungroup()\r\n\r\nmaster2_ek <- data.frame()\r\n\r\nfor(m in 1:length(unique(master2$RN))){\r\n  myTbl <- master2 %>%\r\n    filter(RN == m)\r\n  theDecision <- myTbl %>% na.omit() %>% pull(DECISION) %>% unique()\r\n  myTbl <- myTbl %>%\r\n    mutate(DECISION = ifelse(row_number()==1,theDecision,DECISION),\r\n           DECISION = na.locf(DECISION))\r\n  \r\n  master2_ek <- master2_ek %>% bind_rows(myTbl)\r\n  }\r\nmaster2 <- master2_ek %>%\r\n  select(-RN)\r\nmaster2_cons <- master2 %>%\r\n  filter(DECISION == \"CONSTANT\") %>%\r\n  select(-DATE,-DECISION) %>%\r\n  group_by(day) %>%\r\n  summarise(\r\n    AAR = mean(AR)\r\n    ) %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    CAR = cumsum(AAR)\r\n    ) %>%\r\n  mutate(\r\n    DECISION = \"CONSTANT\"\r\n    )\r\nmaster2_inc <- master2 %>%\r\n  filter(DECISION == \"INCREASED\") %>%\r\n  select(-DATE,-DECISION) %>%\r\n  group_by(day) %>%\r\n  summarise(\r\n    AAR = mean(AR)\r\n) %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    CAR = cumsum(AAR)\r\n    ) %>%\r\n  mutate(\r\n    DECISION = \"INCREASED\"\r\n    )\r\n\r\n\r\nmaster2_dec <- master2 %>%\r\n  filter(DECISION == \"DECREASED\") %>%\r\n  select(-DATE,-DECISION) %>%\r\n  group_by(day) %>%\r\n  summarise(\r\n    AAR = mean(AR)\r\n    ) %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    CAR = cumsum(AAR)\r\n    ) %>%\r\n  mutate(\r\n    DECISION = \"DECREASED\"\r\n    )\r\n\r\n\r\nmaster_all <- rbind(master2_cons,master2_inc,master2_dec)\r\nggplot(master_all, aes(x = day, y = CAR, color = DECISION)) +\r\n  geom_line(size = 1) +\r\n  geom_vline(xintercept = 0) +\r\n  geom_hline(yintercept = 0) +\r\n  theme_minimal() +\r\n  theme(strip.text = element_text(size = 8),\r\n        legend.position = \"none\",\r\n        axis.text = element_text(size = 8),\r\n        axis.title = element_text(size = 8),\r\n        plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5)) +\r\n  facet_wrap(~DECISION) +\r\n  labs(title = \"CAR Graph of Interest Rates by Decisions\")\r\n\r\n\r\n\r\n\r\nWhen the CBRT keeps the interest rates constant, BIST30 prices start\r\nto fall until 10 days before the announcement, up to 4 days before, and\r\nthen it has no effect.\r\nWhen the CBRT lowers the interest rates, BIST30 prices start to move\r\nupwards positively from the 3rd day before the announcement day. After\r\nthe announcement day, we see that the prices are moving in the negative\r\ndirection. Starting from the 5th day, BIST30 prices start to increase\r\nagain.\r\nFinally, we see that when the CBRT raises interest rates, it\r\ndecreases until the 6th day, 10 days before the announcement day. BIST30\r\nmakes a positive jump from 6 days before the announcement day to the 4th\r\nday and then decreases again. After the announcement day, we can say\r\nthat the prices moved in a positive direction, that is, BIST30\r\nincreased.\r\nIn addition to this analysis, we also look at -252 days before and 10\r\ndays after the announcement days.\r\n\r\n\r\n# -252 & 10\r\nbefore2 <- 252\r\nafter2 <- 10\r\n\r\nmaster3 <- data.frame()\r\nfor(i in 1:length(ticker)) {\r\n  for (j in 1:length(eventday)) {\r\n    finalFilter2 <- df_daily %>%\r\n      arrange(Ticker) %>%\r\n      group_by(Ticker) %>%\r\n      mutate(ID = row_number()) %>%\r\n      filter(Ticker == ticker[i])\r\n    \r\n    id2 <- finalFilter2 %>%\r\n      filter(DATE == as.Date(eventday[j])) %>%\r\n      pull(ID)\r\n    \r\n    final2 <- finalFilter2 %>%\r\n      filter(ID >= (id2 - before2) & ID <= (id2 + after2)) %>%\r\n      mutate(DATE = as.Date(DATE)) %>%\r\n      dplyr::select(DATE, Ticker, AR) %>%\r\n      mutate(EventDay = eventday[j])\r\n    \r\n    master3 <- master3 %>% bind_rows(final2)\r\n  }\r\n  \r\n}\r\n\r\nmaster4 <- master3 %>%\r\n  group_by(Ticker,EventDay) %>%\r\n  mutate(\r\n    day = seq(before2*-1,after2,1)\r\n    ) %>%\r\n  ungroup() %>%\r\n  left_join(df_EventDay[,c(1,4)], by = \"DATE\") %>%\r\n  group_by(EventDay) %>%\r\n  mutate(RN = cur_group_id()) %>%\r\n  ungroup()\r\n\r\n\r\nmaster4_ek <- data.frame()\r\nfor(m in 1:length(unique(master4$RN))){\r\n  myTbl2 <- master4 %>%\r\n    filter(RN == m)\r\n  theDecision2 <- myTbl2 %>% na.omit() %>% pull(DECISION) %>% unique()\r\n  myTbl2 <- myTbl2 %>%mutate(DECISION = ifelse(row_number()==1,theDecision,DECISION),\r\n                             DECISION = na.locf(DECISION))\r\n  master4_ek <- master4_ek %>% bind_rows(myTbl2)\r\n}\r\n\r\nmaster4 <- master4_ek %>%\r\n  select(-RN)\r\nmaster4_cons <- master4 %>%\r\n  filter(DECISION == \"CONSTANT\") %>%\r\n  select(-DATE,-DECISION) %>%\r\n  group_by(day) %>%\r\n  summarise(\r\n    AAR = mean(AR)\r\n    ) %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    CAR = cumsum(AAR)\r\n) %>%\r\n  mutate(\r\nDECISION = \"CONSTANT\"\r\n)\r\n\r\nmaster4_inc <- master4 %>%\r\n  filter(DECISION == \"INCREASED\") %>%\r\n  select(-DATE,-DECISION) %>%\r\n  group_by(day) %>%\r\n  summarise(\r\nAAR = mean(AR)\r\n) %>%\r\n  ungroup() %>%\r\nmutate(\r\n  CAR = cumsum(AAR)\r\n) %>%\r\n  mutate(\r\nDECISION = \"INCREASED\"\r\n)\r\n\r\n\r\nmaster4_dec <- master4 %>%\r\n  filter(DECISION == \"DECREASED\") %>%\r\n  select(-DATE,-DECISION) %>%\r\n  group_by(day) %>%\r\n  summarise(\r\n    AAR = mean(AR)\r\n) %>%\r\n  ungroup() %>%\r\n  mutate(\r\nCAR = cumsum(AAR)\r\n) %>%\r\n  mutate(\r\nDECISION = \"DECREASED\"\r\n)\r\n\r\nmaster_all2 <- rbind(master4_cons,master4_inc,master4_dec)\r\n\r\n\r\nggplot(master_all2, aes(x = day, y = CAR, color = DECISION)) +\r\n  geom_line(size = 1) +\r\n  geom_vline(xintercept = 0) +\r\n  geom_hline(yintercept = 0) +\r\n  theme_minimal() +\r\n  theme(strip.text = element_text(size = 8),\r\n        legend.position = \"none\",\r\n        axis.text = element_text(size = 8),\r\n        axis.title = element_text(size = 8),\r\n        plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5)) +\r\n  facet_wrap(~DECISION) +\r\n  labs(title = \"CAR Graph of Interest Rates by Decisions\")\r\n\r\n\r\n\r\n\r\nThe graph shows the price movements of stocks -252 days before and 10\r\ndays after the announcement days.\r\nWe can say that BIST30 prices decrease when interest rates are kept\r\nconstant and decreased, and prices increase in the same way when\r\ninterest rates are increased.\r\nYou can do t-stat in the next step.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-03-eventstudy/eventstudy_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-11-03T18:42:06+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-31-k-means/",
    "title": "K-means Method - Finding the Best Clustering",
    "description": "We will create the best clustering using the k-means method.",
    "author": [
      {
        "name": "Irem Dastan",
        "url": {}
      }
    ],
    "date": "2022-08-31",
    "categories": [
      "Machine Learning",
      "Statistical Methods",
      "K-means"
    ],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse);library(cluster);library(factoextra)\r\nlibrary(caret);library(mice);library(readxl)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# importing data\r\n\r\nwholesale <- read_excel(\"C:/Users/irem/Desktop/wholesale.xlsx\")\r\n\r\n\r\n\r\nFirst, let’s get to know the variables:\r\nFRESH: Annual expenditure on fresh\r\nproduce\r\nMILK: Annual milk expenditure\r\nGROCERY: Grocery products annual\r\nexpenditure\r\nFROZEN: Frozen products annual\r\nexpenditure\r\nDETERGENTS_PAPER: Detergent and paper\r\nannual expenditure\r\nDELICATESSEN: Delicatessen annual\r\nexpenditure\r\nCHANNEL: (Hotel/Restoran/Cafe) or\r\nRetail channel (Nominal)\r\nREGION: Customer area Lisnon, Oporto or\r\nother (Nominal)\r\nI scale units to get rid of outliers.\r\n\r\n\r\nscaleModel <- preProcess(wholesale, method = c(\"center\",\"scale\"))\r\nmodelData <- predict(scaleModel, wholesale)\r\n\r\n\r\n\r\nI’m checking to see if there are any missing observations.\r\n\r\n\r\nmd.pattern(modelData) #missing value does not exist.\r\n\r\n\r\n /\\     /\\\r\n{  `---'  }\r\n{  O   O  }\r\n==>  V <==  No need for mice. This data set is completely observed.\r\n \\  \\|/  /\r\n  `-----'\r\n\r\n    Channel Region Fresh Milk Grocery Frozen Detergents_Paper\r\n440       1      1     1    1       1      1                1\r\n          0      0     0    0       0      0                0\r\n    Delicassen  \r\n440          1 0\r\n             0 0\r\n\r\n\r\n\r\n#Creating model\r\nclusterModel <- kmeans(modelData, centers = 4, \r\n                iter.max = 15, nstart = 15)\r\nclusterModel\r\n\r\n\r\nK-means clustering with 4 clusters of sizes 296, 3, 131, 10\r\n\r\nCluster means:\r\n     Channel      Region       Fresh       Milk    Grocery\r\n1 -0.6822942 -0.04704424  0.07979916 -0.3554503 -0.4344436\r\n2 -0.6895122  0.15948501  3.84044484  3.2957757  0.9852919\r\n3  1.4470045  0.10690343 -0.29218794  0.4286373  0.6330682\r\n4  1.4470045 -0.05577083  0.31347349  3.9174467  4.2707490\r\n        Frozen Detergents_Paper  Delicassen\r\n1  0.073138067       -0.4417690 -0.10544775\r\n2  7.204892918       -0.1527927  6.79967230\r\n3 -0.329983553        0.6495639  0.04416479\r\n4 -0.003570131        4.6129149  0.50279301\r\n\r\nClustering vector:\r\n  [1] 3 3 3 1 3 3 3 3 1 3 3 3 3 3 3 1 3 1 3 1 3 1 1 3 3 3 1 1 3 1 1 1\r\n [33] 1 1 1 3 1 3 3 1 1 1 3 3 3 3 3 4 3 3 1 1 3 3 1 1 4 3 1 1 3 4 3 3\r\n [65] 1 4 1 3 1 1 1 1 1 3 3 1 1 3 1 1 1 3 3 1 3 4 4 1 1 1 1 1 4 1 3 1\r\n [97] 3 1 1 1 3 3 3 1 1 1 3 3 3 3 1 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 3\r\n[129] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 3 3 1 3 3\r\n[161] 3 1 1 3 3 3 3 1 1 1 3 3 1 3 1 3 1 1 1 1 1 2 1 2 1 1 1 1 3 3 1 1\r\n[193] 1 3 1 1 1 3 1 1 3 3 1 1 1 3 1 3 1 3 1 4 1 1 3 1 3 1 3 1 1 1 1 3\r\n[225] 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 4 1 1 1 1\r\n[257] 1 1 1 1 1 1 1 1 3 1 3 1 3 1 1 1 1 1 1 1 1 1 1 3 1 3 1 1 1 1 1 1\r\n[289] 1 1 1 1 1 3 1 3 1 3 3 1 3 3 3 3 3 3 3 1 1 3 1 1 3 1 1 3 1 1 1 3\r\n[321] 1 1 1 1 1 2 1 1 1 1 1 3 1 4 1 3 1 1 1 1 3 3 1 3 1 1 3 3 1 3 1 3\r\n[353] 1 3 1 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 3 1 1 3 1 1 3 1 1 3 1 1 1 1\r\n[385] 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 3 3 1 1 1 1 1 1 3\r\n[417] 3 1 3 1 1 3 1 3 3 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1\r\n\r\nWithin cluster sum of squares by cluster:\r\n[1] 1020.2318  215.6517  437.3645  160.2905\r\n (between_SS / total_SS =  47.8 %)\r\n\r\nAvailable components:\r\n\r\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"    \r\n[5] \"tot.withinss\" \"betweenss\"    \"size\"         \"iter\"        \r\n[9] \"ifault\"      \r\n\r\nfittedCluster <- fitted(clusterModel)\r\n\r\nclusterModel$cluster\r\n\r\n\r\n  [1] 3 3 3 1 3 3 3 3 1 3 3 3 3 3 3 1 3 1 3 1 3 1 1 3 3 3 1 1 3 1 1 1\r\n [33] 1 1 1 3 1 3 3 1 1 1 3 3 3 3 3 4 3 3 1 1 3 3 1 1 4 3 1 1 3 4 3 3\r\n [65] 1 4 1 3 1 1 1 1 1 3 3 1 1 3 1 1 1 3 3 1 3 4 4 1 1 1 1 1 4 1 3 1\r\n [97] 3 1 1 1 3 3 3 1 1 1 3 3 3 3 1 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 3\r\n[129] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 3 3 1 3 3\r\n[161] 3 1 1 3 3 3 3 1 1 1 3 3 1 3 1 3 1 1 1 1 1 2 1 2 1 1 1 1 3 3 1 1\r\n[193] 1 3 1 1 1 3 1 1 3 3 1 1 1 3 1 3 1 3 1 4 1 1 3 1 3 1 3 1 1 1 1 3\r\n[225] 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 4 1 1 1 1\r\n[257] 1 1 1 1 1 1 1 1 3 1 3 1 3 1 1 1 1 1 1 1 1 1 1 3 1 3 1 1 1 1 1 1\r\n[289] 1 1 1 1 1 3 1 3 1 3 3 1 3 3 3 3 3 3 3 1 1 3 1 1 3 1 1 3 1 1 1 3\r\n[321] 1 1 1 1 1 2 1 1 1 1 1 3 1 4 1 3 1 1 1 1 3 3 1 3 1 1 3 3 1 3 1 3\r\n[353] 1 3 1 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 3 1 1 3 1 1 3 1 1 3 1 1 1 1\r\n[385] 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 3 3 1 1 1 1 1 1 3\r\n[417] 3 1 3 1 1 3 1 3 3 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1\r\n\r\nI’m doing a reverse scale here.\r\n\r\n\r\nreversedData <- modelData %>% select(one_of(scaleModel$mean %>% names)) %>%\r\n                  map2_df(scaleModel$std, function(sd, var){var*sd})  %>%\r\n                  map2_df(scaleModel$mean, function(mu, var){var+mu})\r\n\r\nscaleModel$mean \r\n\r\n\r\n         Channel           Region            Fresh             Milk \r\n        1.322727         2.543182     12000.297727      5796.265909 \r\n         Grocery           Frozen Detergents_Paper       Delicassen \r\n     7951.277273      3071.931818      2881.493182      1524.870455 \r\n\r\nreversedData$cluster <- clusterModel$cluster\r\n\r\n\r\nreversedData %>% group_by(cluster) %>% summarise_all(mean)\r\n\r\n\r\n# A tibble: 4 x 9\r\n  cluster Channel Region  Fresh   Milk Grocery Frozen Detergents_Paper\r\n    <int>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>            <dbl>\r\n1       1    1.00   2.51 13010.  3173.   3823.  3427.             775.\r\n2       2    1      2.67 60572. 30120.  17315. 38049.            2153 \r\n3       3    2      2.63  8305.  8960.  13967.  1470.            5979.\r\n4       4    2      2.5  15965. 34708.  48537.  3055.           24875.\r\n# ... with 1 more variable: Delicassen <dbl>\r\n\r\n\r\n\r\nboxplot(Fresh ~ cluster, data = reversedData,\r\n        col=\"#80d7cc\",border=\"pink\")\r\n\r\n\r\n\r\n\r\nThe range in cluster 1 and the range in cluster 4 are almost the\r\nsame. The median of the 3rd cluster and the 4th cluster is similar.\r\n\r\n\r\nfviz_cluster(clusterModel, data = modelData,\r\n             ggtheme = theme_minimal()\r\n             )\r\n\r\n\r\n\r\n\r\nOptimum “k”\r\nK Calculation with Elbow\r\nMethod\r\n\r\n\r\nclusterModel$withinss #cost function\r\n\r\n\r\n[1] 1020.2318  215.6517  437.3645  160.2905\r\n\r\nclusterModel$tot.withinss \r\n\r\n\r\n[1] 1833.538\r\n\r\nwss <- sapply(2:10, FUN = function(x){kmeans(modelData, centers = x, \r\n                        nstart = 10, iter.max = 15)$tot.withinss})\r\n\r\nplot(2:10, wss, type = \"b\")\r\n\r\n\r\n\r\nfviz_nbclust(modelData, kmeans, method = \"wss\")\r\n\r\n\r\n\r\n\r\nK Calculation with\r\nSilhouette Method\r\n\r\n\r\nsilhouette(clusterModel$cluster, dist(modelData))\r\n\r\n\r\n       cluster neighbor   sil_width\r\n  [1,]       3        1  0.37355819\r\n  [2,]       3        1  0.42920620\r\n  [3,]       3        1  0.23506491\r\n  [4,]       1        3  0.45914352\r\n  [5,]       3        1  0.17530370\r\n  [6,]       3        1  0.31555646\r\n  [7,]       3        1  0.30676907\r\n  [8,]       3        1  0.38282887\r\n  [9,]       1        3  0.41154373\r\n [10,]       3        1  0.50823261\r\n [11,]       3        1  0.42750335\r\n [12,]       3        1  0.13984907\r\n [13,]       3        1  0.27744045\r\n [14,]       3        1  0.38694142\r\n [15,]       3        1  0.36442282\r\n [16,]       1        3  0.46915071\r\n [17,]       3        1  0.46288391\r\n [18,]       1        3  0.33310271\r\n [19,]       3        1  0.32248382\r\n [20,]       1        3  0.36150808\r\n [21,]       3        1  0.24156874\r\n [22,]       1        3  0.49248284\r\n [23,]       1        3  0.29687637\r\n [24,]       3        4  0.12069406\r\n [25,]       3        1  0.30097041\r\n [26,]       3        1  0.31868219\r\n [27,]       1        3  0.50662730\r\n [28,]       1        3  0.47953941\r\n [29,]       3        1  0.38716473\r\n [30,]       1        3  0.29738327\r\n [31,]       1        3  0.31004413\r\n [32,]       1        3  0.44539988\r\n [33,]       1        3  0.43473774\r\n [34,]       1        3  0.36141265\r\n [35,]       1        3  0.44200170\r\n [36,]       3        1  0.41374814\r\n [37,]       1        3  0.30346113\r\n [38,]       3        1  0.45887854\r\n [39,]       3        1  0.47304671\r\n [40,]       1        3  0.23760603\r\n [41,]       1        3  0.27984785\r\n [42,]       1        3  0.38206340\r\n [43,]       3        1  0.47398083\r\n [44,]       3        1  0.46348721\r\n [45,]       3        1  0.43018426\r\n [46,]       3        1  0.38214253\r\n [47,]       3        1  0.48087479\r\n [48,]       4        3  0.38141847\r\n [49,]       3        1  0.44822227\r\n [50,]       3        4  0.33332161\r\n [51,]       1        3  0.47219973\r\n [52,]       1        3  0.38008365\r\n [53,]       3        1  0.08958941\r\n [54,]       3        1  0.46123988\r\n [55,]       1        3  0.42858355\r\n [56,]       1        3  0.42272643\r\n [57,]       4        3 -0.10182080\r\n [58,]       3        1  0.48629465\r\n [59,]       1        3  0.48482054\r\n [60,]       1        3  0.31874080\r\n [61,]       3        1  0.34269869\r\n [62,]       4        3  0.41550515\r\n [63,]       3        1  0.34333119\r\n [64,]       3        1  0.49659390\r\n [65,]       1        3  0.47025066\r\n [66,]       4        3  0.17164203\r\n [67,]       1        3  0.31549916\r\n [68,]       3        1  0.40087008\r\n [69,]       1        3  0.34849739\r\n [70,]       1        3  0.47845096\r\n [71,]       1        3  0.39379264\r\n [72,]       1        3  0.02676125\r\n [73,]       1        3  0.37467800\r\n [74,]       3        1  0.12862857\r\n [75,]       3        1  0.36989976\r\n [76,]       1        3  0.47992034\r\n [77,]       1        3  0.37150145\r\n [78,]       3        1  0.42843697\r\n [79,]       1        3  0.50248514\r\n [80,]       1        3  0.41912887\r\n [81,]       1        3  0.47355546\r\n [82,]       3        1  0.48247178\r\n [83,]       3        1  0.43931840\r\n [84,]       1        3  0.47195726\r\n [85,]       3        1  0.28161978\r\n [86,]       4        3  0.39089340\r\n [87,]       4        3  0.25492925\r\n [88,]       1        3  0.08954934\r\n [89,]       1        3  0.39768825\r\n [90,]       1        3  0.38708226\r\n [91,]       1        3  0.50758707\r\n [92,]       1        3  0.42921254\r\n [93,]       4        3  0.02147292\r\n [94,]       1        3  0.11956719\r\n [95,]       3        1  0.45923962\r\n [96,]       1        3  0.39607519\r\n [97,]       3        1  0.32373037\r\n [98,]       1        3  0.44041210\r\n [99,]       1        3  0.44322499\r\n[100,]       1        3  0.48246085\r\n[101,]       3        1  0.44585231\r\n[102,]       3        1  0.50273386\r\n[103,]       3        1  0.40145904\r\n[104,]       1        3  0.17004264\r\n[105,]       1        3  0.47285853\r\n[106,]       1        3  0.47492519\r\n[107,]       3        1  0.46159765\r\n[108,]       3        1  0.49645456\r\n[109,]       3        1  0.36214506\r\n[110,]       3        1  0.33799707\r\n[111,]       1        3  0.50119125\r\n[112,]       3        1  0.49384178\r\n[113,]       1        3  0.40266365\r\n[114,]       1        3  0.49598957\r\n[115,]       1        3  0.49019488\r\n[116,]       1        3  0.50597195\r\n[117,]       1        3  0.48993422\r\n[118,]       1        3  0.45952277\r\n[119,]       1        3  0.46916745\r\n[120,]       1        3  0.49935322\r\n[121,]       1        3  0.48901930\r\n[122,]       1        3  0.47524012\r\n[123,]       1        3  0.50594792\r\n[124,]       3        1  0.34928222\r\n[125,]       1        3  0.36133157\r\n[126,]       1        3  0.14334739\r\n[127,]       1        3  0.43680761\r\n[128,]       3        1  0.31611115\r\n[129,]       1        3  0.31883136\r\n[130,]       1        3  0.31507302\r\n[131,]       1        3  0.46721527\r\n[132,]       1        3  0.45158071\r\n[133,]       1        3  0.47075941\r\n[134,]       1        3  0.48617362\r\n[135,]       1        3  0.48719072\r\n[136,]       1        3  0.48621986\r\n[137,]       1        3  0.31737489\r\n[138,]       1        3  0.31815141\r\n[139,]       1        3  0.39252367\r\n[140,]       1        3  0.44420355\r\n[141,]       1        3  0.40064496\r\n[142,]       1        3  0.25040416\r\n[143,]       1        3  0.29036292\r\n[144,]       1        3  0.43869937\r\n[145,]       1        3  0.44203643\r\n[146,]       3        1  0.33668747\r\n[147,]       1        3  0.49122514\r\n[148,]       1        3  0.47864334\r\n[149,]       1        3  0.49041734\r\n[150,]       1        3  0.38304781\r\n[151,]       1        3  0.48273994\r\n[152,]       1        3  0.42773284\r\n[153,]       1        3  0.47855459\r\n[154,]       1        3  0.35893712\r\n[155,]       1        3  0.43116762\r\n[156,]       3        1  0.47326145\r\n[157,]       3        1  0.45644839\r\n[158,]       1        3  0.48504542\r\n[159,]       3        1  0.42862056\r\n[160,]       3        1  0.47950315\r\n[161,]       3        1  0.41434722\r\n[162,]       1        3  0.47694610\r\n[163,]       1        3  0.49371048\r\n[164,]       3        1  0.41658677\r\n[165,]       3        1  0.39233591\r\n[166,]       3        1  0.43955047\r\n[167,]       3        1  0.40781484\r\n[168,]       1        3  0.42490263\r\n[169,]       1        3  0.49065356\r\n[170,]       1        3  0.49470375\r\n[171,]       3        1  0.48029363\r\n[172,]       3        1  0.33401847\r\n[173,]       1        3  0.32309458\r\n[174,]       3        1  0.47668439\r\n[175,]       1        3  0.43008664\r\n[176,]       3        1  0.45803485\r\n[177,]       1        3  0.24718967\r\n[178,]       1        3  0.40098216\r\n[179,]       1        3  0.41971621\r\n[180,]       1        3  0.42986330\r\n[181,]       1        3  0.33191953\r\n[182,]       2        1 -0.28528892\r\n[183,]       1        3  0.08729351\r\n[184,]       2        3  0.15008921\r\n[185,]       1        3  0.40861617\r\n[186,]       1        3  0.45415628\r\n[187,]       1        3  0.47099913\r\n[188,]       1        3  0.24802548\r\n[189,]       3        1  0.46540330\r\n[190,]       3        1  0.44936267\r\n[191,]       1        3  0.42257825\r\n[192,]       1        3  0.48645058\r\n[193,]       1        3  0.47536258\r\n[194,]       3        1  0.42518881\r\n[195,]       1        3  0.48199920\r\n[196,]       1        3  0.40763001\r\n[197,]       1        3  0.19696039\r\n[198,]       3        1  0.24343766\r\n[199,]       1        3  0.33669081\r\n[200,]       1        3  0.34529822\r\n[201,]       3        1  0.33402418\r\n[202,]       3        1  0.32827953\r\n[203,]       1        3  0.16534868\r\n[204,]       1        3  0.31148831\r\n[205,]       1        3  0.31826241\r\n[206,]       3        1  0.34325373\r\n[207,]       1        3  0.34897816\r\n[208,]       3        1  0.18240688\r\n[209,]       1        3  0.25943629\r\n[210,]       3        1  0.33501539\r\n[211,]       1        3  0.35158878\r\n[212,]       4        3  0.15269972\r\n[213,]       1        3  0.34698152\r\n[214,]       1        3  0.21927604\r\n[215,]       3        1  0.26738101\r\n[216,]       1        3  0.04176371\r\n[217,]       3        4  0.25115801\r\n[218,]       1        3  0.36311709\r\n[219,]       3        1  0.23345203\r\n[220,]       1        3  0.35018521\r\n[221,]       1        3  0.36676086\r\n[222,]       1        3  0.16820371\r\n[223,]       1        3  0.33490570\r\n[224,]       3        1  0.05608619\r\n[225,]       1        3  0.35181231\r\n[226,]       1        3  0.33361678\r\n[227,]       3        1  0.14311093\r\n[228,]       1        3  0.34603227\r\n[229,]       1        3  0.26894367\r\n[230,]       1        3  0.34260346\r\n[231,]       3        1  0.05508568\r\n[232,]       1        3  0.23551341\r\n[233,]       1        3  0.32202494\r\n[234,]       1        3  0.29840220\r\n[235,]       1        3  0.34266211\r\n[236,]       1        3  0.28836771\r\n[237,]       1        3  0.35551388\r\n[238,]       1        3  0.35899210\r\n[239,]       1        3  0.35567233\r\n[240,]       1        3  0.24184457\r\n[241,]       1        3  0.27515792\r\n[242,]       1        3  0.34002688\r\n[243,]       1        3  0.36047111\r\n[244,]       1        3  0.29985147\r\n[245,]       1        3  0.18897605\r\n[246,]       3        1  0.30325475\r\n[247,]       1        3  0.35515569\r\n[248,]       1        3  0.37100729\r\n[249,]       1        3  0.32873256\r\n[250,]       1        3  0.33807492\r\n[251,]       1        3  0.33992660\r\n[252,]       4        3 -0.02490560\r\n[253,]       1        3  0.32540169\r\n[254,]       1        3  0.17201201\r\n[255,]       1        3  0.15502567\r\n[256,]       1        3  0.32557325\r\n[257,]       1        3  0.31505877\r\n[258,]       1        3  0.31618367\r\n[259,]       1        3  0.20573178\r\n[260,]       1        3  0.19858004\r\n[261,]       1        3  0.32480945\r\n[262,]       1        3  0.35387762\r\n[263,]       1        3  0.34113578\r\n[264,]       1        3  0.28379501\r\n[265,]       3        1  0.30995183\r\n[266,]       1        3  0.05634869\r\n[267,]       3        1  0.30534220\r\n[268,]       1        3  0.32486555\r\n[269,]       3        1  0.30401755\r\n[270,]       1        3  0.36759146\r\n[271,]       1        3  0.35042011\r\n[272,]       1        3  0.31292883\r\n[273,]       1        3  0.24451429\r\n[274,]       1        3  0.35699129\r\n[275,]       1        3  0.44023157\r\n[276,]       1        3  0.44731244\r\n[277,]       1        3  0.37217089\r\n[278,]       1        3  0.28375269\r\n[279,]       1        3  0.47970342\r\n[280,]       3        1  0.37070234\r\n[281,]       1        3  0.46340626\r\n[282,]       3        1  0.33195287\r\n[283,]       1        3  0.26158848\r\n[284,]       1        3  0.37382786\r\n[285,]       1        3  0.14926568\r\n[286,]       1        3  0.31783015\r\n[287,]       1        3  0.48056051\r\n[288,]       1        3  0.43837402\r\n[289,]       1        3  0.47872790\r\n[290,]       1        3  0.31685902\r\n[291,]       1        3  0.44027919\r\n[292,]       1        3  0.48454673\r\n[293,]       1        3  0.44839086\r\n[294,]       3        1  0.43151571\r\n[295,]       1        3  0.39926672\r\n[296,]       3        1  0.18459551\r\n[297,]       1        3  0.45351092\r\n[298,]       3        1  0.26672514\r\n[299,]       3        1  0.34973423\r\n[300,]       1        3  0.40504691\r\n[301,]       3        1  0.24952735\r\n[302,]       3        1  0.44791954\r\n[303,]       3        1  0.37609132\r\n[304,]       3        1  0.38798736\r\n[305,]       3        1  0.41746796\r\n[306,]       3        1  0.35473358\r\n[307,]       3        1  0.45509056\r\n[308,]       1        3  0.45019105\r\n[309,]       1        3  0.44087176\r\n[310,]       3        1  0.38387608\r\n[311,]       1        3  0.34819467\r\n[312,]       1        3  0.36231478\r\n[313,]       3        1  0.33987396\r\n[314,]       1        3  0.46857455\r\n[315,]       1        3  0.41719492\r\n[316,]       3        1  0.37223257\r\n[317,]       1        3  0.46567554\r\n[318,]       1        3  0.37593054\r\n[319,]       1        3  0.45261073\r\n[320,]       3        1  0.36073020\r\n[321,]       1        3  0.40699767\r\n[322,]       1        3  0.45399578\r\n[323,]       1        3  0.45291391\r\n[324,]       1        3  0.35010494\r\n[325,]       1        3  0.41699408\r\n[326,]       2        1 -0.10719072\r\n[327,]       1        3  0.45393530\r\n[328,]       1        3  0.41186050\r\n[329,]       1        3  0.42793573\r\n[330,]       1        3  0.43675500\r\n[331,]       1        3  0.45803029\r\n[332,]       3        1  0.42418446\r\n[333,]       1        3  0.42285518\r\n[334,]       4        3  0.23113100\r\n[335,]       1        3  0.02381463\r\n[336,]       3        1  0.25390623\r\n[337,]       1        3  0.45862834\r\n[338,]       1        3  0.42658799\r\n[339,]       1        3  0.26491718\r\n[340,]       1        3  0.35987323\r\n[341,]       3        1  0.42039587\r\n[342,]       3        1  0.44941579\r\n[343,]       1        3  0.26250322\r\n[344,]       3        1  0.38812809\r\n[345,]       1        3  0.47708626\r\n[346,]       1        3  0.29995958\r\n[347,]       3        1  0.48360358\r\n[348,]       3        1  0.30395956\r\n[349,]       1        3  0.46211930\r\n[350,]       3        1  0.45343196\r\n[351,]       1        3  0.47981236\r\n[352,]       3        1  0.44251389\r\n[353,]       1        3  0.44424632\r\n[354,]       3        1  0.46951044\r\n[355,]       1        3  0.39691871\r\n[356,]       1        3  0.42908542\r\n[357,]       1        3  0.46706597\r\n[358,]       3        1  0.38997030\r\n[359,]       1        3  0.16374206\r\n[360,]       1        3  0.40151451\r\n[361,]       1        3  0.47427999\r\n[362,]       1        3  0.48215429\r\n[363,]       1        3  0.45370753\r\n[364,]       1        3  0.43597284\r\n[365,]       1        3  0.46448225\r\n[366,]       3        1  0.39443789\r\n[367,]       1        3  0.49668354\r\n[368,]       1        3  0.47576168\r\n[369,]       1        3  0.46179696\r\n[370,]       1        3  0.48643111\r\n[371,]       3        1  0.04959055\r\n[372,]       1        3  0.43186364\r\n[373,]       1        3  0.33771000\r\n[374,]       3        1  0.29743331\r\n[375,]       1        3  0.49271607\r\n[376,]       1        3  0.47283265\r\n[377,]       3        1  0.40934267\r\n[378,]       1        3  0.32817315\r\n[379,]       1        3  0.45024435\r\n[380,]       3        1  0.30550501\r\n[381,]       1        3  0.42085188\r\n[382,]       1        3  0.39855879\r\n[383,]       1        3  0.26474702\r\n[384,]       1        3  0.45417802\r\n[385,]       1        3  0.02685022\r\n[386,]       1        3  0.51014398\r\n[387,]       1        3  0.44606705\r\n[388,]       1        3  0.47131037\r\n[389,]       1        3  0.50392199\r\n[390,]       1        3  0.50993138\r\n[391,]       1        3  0.46105024\r\n[392,]       1        3  0.44672237\r\n[393,]       1        3  0.41859897\r\n[394,]       1        3  0.37568104\r\n[395,]       1        3  0.49539363\r\n[396,]       1        3  0.50165925\r\n[397,]       3        1  0.41186807\r\n[398,]       1        3  0.47246180\r\n[399,]       1        3  0.49078885\r\n[400,]       1        3  0.50024330\r\n[401,]       1        3  0.48770085\r\n[402,]       1        3  0.32728814\r\n[403,]       1        3  0.37941534\r\n[404,]       1        3  0.29826480\r\n[405,]       1        3  0.45830981\r\n[406,]       1        3  0.49681944\r\n[407,]       1        3  0.35589657\r\n[408,]       3        1  0.48810598\r\n[409,]       3        1  0.30050860\r\n[410,]       1        3  0.30030960\r\n[411,]       1        3  0.43914490\r\n[412,]       1        3  0.35098296\r\n[413,]       1        3  0.23906312\r\n[414,]       1        3  0.22090343\r\n[415,]       1        3  0.45393505\r\n[416,]       3        1  0.40075454\r\n[417,]       3        1  0.48834329\r\n[418,]       1        3  0.25842826\r\n[419,]       3        1  0.48995046\r\n[420,]       1        3  0.45220436\r\n[421,]       1        3  0.09906878\r\n[422,]       3        1  0.34567647\r\n[423,]       1        3  0.40509502\r\n[424,]       3        1  0.20862012\r\n[425,]       3        1  0.32274230\r\n[426,]       1        3  0.30417541\r\n[427,]       1        3  0.13106038\r\n[428,]       1        3  0.18633007\r\n[429,]       1        3  0.41000999\r\n[430,]       1        3  0.43997321\r\n[431,]       1        3  0.22854768\r\n[432,]       1        3  0.29402515\r\n[433,]       1        3  0.42134485\r\n[434,]       1        3  0.45315172\r\n[435,]       1        3  0.37824588\r\n[436,]       1        3  0.17185246\r\n[437,]       1        3  0.34343919\r\n[438,]       3        4  0.36682210\r\n[439,]       1        3  0.47554004\r\n[440,]       1        3  0.44101326\r\nattr(,\"Ordered\")\r\n[1] FALSE\r\nattr(,\"call\")\r\nsilhouette.default(x = clusterModel$cluster, dist = dist(modelData))\r\nattr(,\"class\")\r\n[1] \"silhouette\"\r\n\r\n# The model with silhouette score max will be the best k model.\r\n\r\nsilScore <- function(x){\r\n             model <- kmeans(modelData, centers = x , nstart = 10, iter.max = 15)\r\n             sil <- silhouette(model$cluster, dist(modelData))[,3]\r\n             score <- mean(sil)\r\n             return(score)\r\n             }\r\n\r\nscores <- sapply(2:10, FUN = silScore)\r\n\r\nscores\r\n\r\n\r\n[1] 0.3732334 0.3598428 0.3674071 0.3562636 0.3515995 0.3541891\r\n[7] 0.3499041 0.3293357 0.3599715\r\n\r\nplot(2:10, scores, type = \"b\") \r\n\r\n\r\n\r\n\r\nMax score is best so “2”\r\nLet’s sort.\r\n\r\n\r\nfviz_nbclust(modelData, kmeans, method = \"silhouette\")\r\n\r\n\r\n\r\n\r\nAccording to the code above, the optimal 3 point came out because we\r\ngave nstart a random number.\r\n\r\n\r\nclusterModelK2 <- kmeans(modelData, centers = 2, nstart = 50, iter.max = 20)\r\nclusterModelK3 <- kmeans(modelData, centers = 3, nstart = 50, iter.max = 20)\r\n\r\nfviz_cluster(clusterModelK2, modelData)\r\n\r\n\r\n\r\n\r\nIn the code above there are outliers in the blue region at the\r\nextremes, the density is at the top.\r\n\r\n\r\nfviz_cluster(clusterModelK3, modelData)\r\n\r\n\r\n\r\n\r\nIn the above code, it created a cluster of outliers on the left.\r\n\r\n\r\nreversedData$clusterK2 <- clusterModelK2$cluster\r\nreversedData$clusterK3 <- clusterModelK3$cluster\r\n\r\nreversedData %>% group_by(clusterK2) %>% summarise_all(mean) \r\n\r\n\r\n# A tibble: 2 x 11\r\n  clusterK2 Channel Region  Fresh   Milk Grocery Frozen\r\n      <int>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>\r\n1         1    1.03   2.50 13576.  3318.   3944.  3667.\r\n2         2    1.99   2.63  8441. 11394.  17005.  1727.\r\n# ... with 4 more variables: Detergents_Paper <dbl>,\r\n#   Delicassen <dbl>, cluster <dbl>, clusterK3 <dbl>\r\n\r\nMore milk intake in cluster 2.\r\n\r\n\r\nreversedData %>% group_by(clusterK3) %>% summarise_all(mean)\r\n\r\n\r\n# A tibble: 3 x 11\r\n  clusterK3 Channel Region  Fresh   Milk Grocery Frozen\r\n      <int>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>\r\n1         1    1.79   2.57 26267. 33848.  39952. 10703.\r\n2         2    1.00   2.51 13010.  3173.   3823.  3427.\r\n3         3    2      2.62  8166.  8749.  13905.  1442.\r\n# ... with 4 more variables: Detergents_Paper <dbl>,\r\n#   Delicassen <dbl>, cluster <dbl>, clusterK2 <dbl>\r\n\r\nWhen we look at the region, we see that there is no distinction\r\naccording to this. Meat intake is higher in cluster 3.\r\n1 and 3 restaurants 2nd cluster hotel.\r\nAs a result, we can segment customers according to this cluster and\r\norganize campaigns accordingly. The optimum number of clusters is 2 and\r\n3. Whichever is more meaningful for the company, that is, profitable, we\r\ncan use that cluster as customer segmentation.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-31-k-means/kmeans.jpg",
    "last_modified": "2022-08-31T18:59:44+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-30-linearalgebra/",
    "title": "Introduction to Econometrics: Linear Algebra",
    "description": "In this series, I will share both my theoretical and applied knowledge about econometrics. In this post, I will make important theoretical reminders about linear algebra.",
    "author": [
      {
        "name": "Irem Dastan",
        "url": {}
      }
    ],
    "date": "2022-08-30",
    "categories": [
      "Econometrics",
      "Linear Algebra"
    ],
    "contents": "\r\nI think theoretical knowledge about econometrics is very important.\r\nFor example, we can do regression analysis with a simple code by\r\nbuilding a model, but what is this analysis? what does it do? What is\r\n\\(\\beta\\) in the model? I think the\r\nquestions are much more important. If we can understand this part well,\r\nwe will get more accurate results when coding and interpreting\r\nanalysis.\r\nIn addition to finance, in this series that I have just started, I\r\nwill both prove and show practically about econometrics.\r\nI hope that will be useful!\r\nAnd I hope you like theoretical econometrics!\r\n\r\n\r\n\r\nI’ll continue with linear algebra in the next post. I’ll do it\r\npractically later.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-30-linearalgebra/1.jpg",
    "last_modified": "2022-08-30T17:40:35+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-26-equity-valuation/",
    "title": "Equity Valuation Methods - Dividend Discount Model",
    "description": "I will evaluate using historical dividend data for TUPRS stock listed on Borsa Istanbul (BIST).",
    "author": [
      {
        "name": "Irem Dastan",
        "url": {}
      }
    ],
    "date": "2022-08-26",
    "categories": [
      "Finance",
      "Dividend",
      "Stock Prices"
    ],
    "contents": "\r\n\r\n\r\nlibrary(readxl);library(tidyverse);library(openxlsx);\r\nlibrary(knitr);library(data.table);library(quantmod)\r\n\r\n\r\n\r\nIn this study, I will use TUPRS stock.\r\n1-\r\nEstimation of equity per share (EPS) using dividend discount\r\nmodels.\r\nI am using dividends of TUPRS stock distributed from 2007 to 2019. I\r\ngot this data from the “investing.com” website.\r\n\r\n\r\ndata <- read_excel(\"ass_2.xlsx\")\r\n\r\n\r\n\r\nHere, I calculate dividend growth rate.\r\n\r\n\r\ndata <- data %>% \r\n  mutate(lag_div=shift(Dividend, 1, type= \"lag\"),\r\n         div_growth_rate= (Dividend-lag_div)/lag_div) %>% \r\n  select(c(-\"lag_div\")) \r\n\r\narithmetic_g <- mean(data$div_growth_rate, na.rm = TRUE)\r\n# geometric_g1 <- geometric.mean(data$div_growth_rate, na.rm = TRUE)\r\ngeometric_g <- 0.1723\r\n\r\n\r\n\r\nWe calculate the dividend growth rate (g) both geometrically and\r\narithmetically. We use the dividend growth rate that we calculate\r\ngeometrically because the arithmetic g value is 40%, which is not very\r\nrealistic. The g value of the geometric mean is 17%. That’s why we\r\nprefer g, which we calculate with the geometric mean.\r\nWe then use the CAPM formula to find the required return. CAPM\r\nformula is as follows\r\n\\(E(R_{i}) = Rf + \\beta (E(R_{m}) -\r\nR_{f})\\)\r\nData obtained from yahoo between May 31, 2007 and March 28, 2019 is\r\nused for TUPRS stock.\r\n\r\n\r\nstock <- data.frame(getSymbols(\"TUPRS.IS\",\r\n                               src=\"yahoo\",\r\n                               auto.assign = FALSE,\r\n                               from = \"2007-05-31\",\r\n                               to = \"2019-03-28\"))\r\n\r\nmarket <- data.frame(getSymbols(\"XU100.IS\",\r\n                                src=\"yahoo\",\r\n                                auto.assign = FALSE,\r\n                                from = \"2007-05-31\",\r\n                                to = \"2019-03-28\"))\r\n\r\ndata <- merge(stock, market, by = \"row.names\")\r\n\r\n# prices\r\npr.stock = data$TUPRS.IS.Adjusted\r\npr.market = data$XU100.IS.Adjusted\r\n\r\n# visualize price data to see relationship\r\n\r\nnormalization <- function(x){\r\n  (x - min(x)) / (max(x) - min(x))\r\n}\r\n\r\ndata %>% \r\n  select(TUPRS.IS.Adjusted,XU100.IS.Adjusted) %>% \r\n  na.omit() %>% \r\n  mutate(t = seq(1,nrow(.),1),\r\n         TUPRS.IS.Adjusted = normalization(TUPRS.IS.Adjusted),\r\n         XU100.IS.Adjusted = normalization(XU100.IS.Adjusted)) %>% \r\n  pivot_longer(!t, names_to = \"vars\", values_to = \"vals\") %>% \r\n  ggplot(aes(x = t, y = vals, group = vars, color = vars)) +\r\n  geom_line() +\r\n  scale_color_manual(values = c(\"#813B3D\",\"#65738E\")) +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.caption = element_text(face = \"italic\")) +\r\n  labs(\r\n    caption = \"Data is normalized\"\r\n  )\r\n\r\n\r\n\r\n# returns\r\nret.stock <- diff(pr.stock) / pr.stock[-length(pr.stock)]\r\nret.market <- diff(pr.market) / pr.market[-length(pr.market)]\r\n\r\ndt <- data.frame(\r\n  t = seq(1,length(ret.stock),1),\r\n  ret.stock = ret.stock,\r\n  ret.market = ret.market\r\n)\r\n\r\n# summary statistics and histogram\r\ndt %>% \r\n  pivot_longer(!t, names_to = \"vars\", values_to = \"vals\") %>% \r\n  ggplot(aes(x = vals, fill = vars)) +\r\n  geom_density(alpha = .5) +\r\n  scale_fill_manual(values = c(\"red\",\"purple\")) +\r\n  theme_minimal() +\r\n  theme(axis.text.y = element_blank(),\r\n        axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\")\r\n\r\n\r\n\r\nsummary(ret.market)\r\n\r\n\r\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \r\n-0.10474 -0.00801  0.00073  0.00033  0.00923  0.12893      151 \r\n\r\nsummary(ret.stock)\r\n\r\n\r\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's \r\n-0.097222 -0.009615  0.000000  0.001052  0.012500  0.161290        25 \r\n\r\n# correlation\r\nres.cor <- cor.test(ret.stock, ret.market)\r\n# below line is to obtain correlation estimate in cor.test result\r\nv.cor <- as.numeric(res.cor$estimate)\r\n\r\n# variances\r\nvar.stock <- var(ret.stock, na.rm = TRUE)\r\nvar.market <- var(ret.market, na.rm = TRUE)\r\n\r\n# risk free rate for Turkey \r\nrf <- 0.17\r\n\r\nexc.market <- ret.market - rf/250 #Rm-Rf (excess market)\r\nexc.stock <- ret.stock - rf/250 #Ri-Rf (excess stock)\r\n\r\nreg <- lm(exc.stock ~ exc.market)\r\nsummary(reg)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = exc.stock ~ exc.market)\r\n\r\nResiduals:\r\n      Min        1Q    Median        3Q       Max \r\n-0.086592 -0.009943 -0.000638  0.010110  0.150381 \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value            Pr(>|t|)    \r\n(Intercept) 0.0006139  0.0003326   1.846               0.065 .  \r\nexc.market  0.7223823  0.0204305  35.358 <0.0000000000000002 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 0.01794 on 2909 degrees of freedom\r\n  (151 observations deleted due to missingness)\r\nMultiple R-squared:  0.3006,    Adjusted R-squared:  0.3003 \r\nF-statistic:  1250 on 1 and 2909 DF,  p-value: < 0.00000000000000022\r\n\r\nreg$coefficients\r\n\r\n\r\n (Intercept)   exc.market \r\n0.0006139034 0.7223822894 \r\n\r\n# E[Rm] --> historical average of Rm, annualized\r\nErm <- mean(ret.market, na.rm = TRUE) * 250\r\n\r\n# E[Ri] <- Rf + Beta * (E[Rm] - Rf)\r\n\r\nbeta <- 0.7223822712\r\n\r\nri <- rf + beta * (Erm - rf)\r\n\r\n\r\n\r\nWe take the risk free rate as 17% for Turkey. To find the excess\r\nmarket, we subtract the risk free rate from the market return and divide\r\nby 250 to find this value on a daily basis. We do the same for excess\r\nstock.\r\nThen we construct a single linear regression model. Our dependent\r\nvariable in the model is excess stock, and the independent variable is\r\nexcess market. As a result, the value of the beta coefficient is 0.7223.\r\nWe calculate the Expected \\(R_{m}\\) by\r\naveraging the market return and multiply it by 250 because we want it on\r\nan annual basis.\r\nIf we apply the results to the CAPM formula;\r\n\\(E(R_{i}) = Rf + \\beta (E(R_{m}) -\r\nR_{f})\\)\r\n\\(R_{f}= 0.17\\)\r\n\\(\\beta= 0.7223\\) and\r\n\\(E(R_{m})= 0.0825\\)\r\nHere the required return value is 0.1067.\r\nWe value the price of TUPRS stock with the Gordon Growth model based\r\non the fact that it equals the sum of all future dividend payments. The\r\nmodel formula is as follows\r\n\\(V_{0}=\\frac{D_{0}*(1+g)}{(r_{i}-g)}\\)\r\nwhere\r\n$D_{0} $ is price of the last dividend distributed.\r\n\\(g\\) g is the dividend growth\r\nrate.\r\n\\(r_{i}\\) is required return.\r\nWe calculated g and ri above. If we substitute it in the formula;\r\n\r\n\r\nD_0 <- 15.15\r\n\r\ng <- 0.1723\r\n\r\nri <- 0.1067\r\n\r\n\r\nV_0 <- (D_0 * ( 1+ g)) / (ri - g)\r\n\r\n\r\n\r\nWe find the value of V0 -270.737\r\nThe result is negative because the dividend growth rate, that is, g,\r\nis greater than r.\r\nBut to get an infinite stream of dividends to converge to a finite\r\nstock value at t = 0, we must assume that the required return on common\r\nstock is greater than the growth rate in dividends. So r > g must\r\nbe.\r\nLet’s see how the price will change if we take the dividend\r\ngrowth rate (g) the same and assume \\(r_{i}\\) is 20%. That is, with the\r\ncondition r > g\r\n\r\n\r\nD_0 <- 15.15\r\n\r\ng <- 0.1723\r\n\r\nri <- 0.20\r\n\r\n\r\nV_0 <- (D_0 * ( 1+ g)) / (ri - g)\r\n\r\n\r\n\r\nWhen we assume \\(r_{i}\\) as 20%,\r\nthat is, when r > g, as in the assumption of the model, the price\r\nbecomes 641.1677.\r\nLet’s see how the price will change if we take the dividend\r\ngrowth rate (g) the same and assume \\(r_{i}\\) is 25%.\r\n\r\n\r\nD_0 <- 15.15\r\n\r\ng <- 0.1723\r\n\r\nri <- 0.25\r\n\r\n\r\nV_0 <- (D_0 * ( 1+ g)) / (ri - g)\r\n\r\n\r\n\r\nWhen we assume \\(r_{i}\\) as 25%, the\r\nprice becomes 228.5759. Assuming \\(R_{i}\\) as 25%, we find the result very\r\nclose to the current value of TUPRS, that is, 259.50 (as of May 30,\r\n2022).\r\nSo far, we have used the dividend data of TUPRS stock between 2007\r\nand 2019. Now, let’s do the same calculations using the data between\r\n2016 and 2019.\r\n\r\n\r\n#for 2016 and 2019\r\n\r\n# retrieve data from yahoo\r\nstock <- data.frame(getSymbols(\"TUPRS.IS\",\r\n                               src=\"yahoo\",\r\n                               auto.assign = FALSE,\r\n                               from = \"2016-01-01\",\r\n                               to = \"2019-01-01\"))\r\n\r\nmarket <- data.frame(getSymbols(\"XU100.IS\",\r\n                                src=\"yahoo\",\r\n                                auto.assign = FALSE,\r\n                                from = \"2016-01-01\",\r\n                                to = \"2019-01-01\"))\r\n\r\ndata <- merge(stock, market, by = \"row.names\")\r\n\r\n# prices\r\npr.stock = data$TUPRS.IS.Adjusted\r\npr.market = data$XU100.IS.Adjusted\r\n\r\n\r\n# visualize price data to see relationship\r\n\r\nnormalization1 <- function(x){\r\n  (x - min(x)) / (max(x) - min(x))\r\n}\r\n\r\ndata %>% \r\n  select(TUPRS.IS.Adjusted,XU100.IS.Adjusted) %>% \r\n  na.omit() %>% \r\n  mutate(t = seq(1,nrow(.),1),\r\n         TUPRS.IS.Adjusted = normalization(TUPRS.IS.Adjusted),\r\n         XU100.IS.Adjusted = normalization(XU100.IS.Adjusted)) %>% \r\n  pivot_longer(!t, names_to = \"vars\", values_to = \"vals\") %>% \r\n  ggplot(aes(x = t, y = vals, group = vars, color = vars)) +\r\n  geom_line() +\r\n  scale_color_manual(values = c(\"lightblue\",\"#9B5134\")) +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.caption = element_text(face = \"italic\")) +\r\n  labs(\r\n    caption = \"Data is normalized\"\r\n  )\r\n\r\n\r\n\r\n# summary statistics and histogram\r\n\r\ndt %>% \r\n  pivot_longer(!t, names_to = \"vars\", values_to = \"vals\") %>% \r\n  ggplot(aes(x = vals, fill = vars)) +\r\n  geom_density(alpha = .5) +\r\n  scale_fill_manual(values = c(\"yellow\",\"blue\")) +\r\n  theme_minimal() +\r\n  theme(axis.text.y = element_blank(),\r\n        axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\")\r\n\r\n\r\n\r\nsummary(ret.market)\r\n\r\n\r\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \r\n-0.10474 -0.00801  0.00073  0.00033  0.00923  0.12893      151 \r\n\r\nsummary(ret.stock)\r\n\r\n\r\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's \r\n-0.097222 -0.009615  0.000000  0.001052  0.012500  0.161290        25 \r\n\r\n# correlation\r\nres.cor <- cor.test(ret.stock, ret.market)\r\n# below line is to obtain correlation estimate in cor.test result\r\nv.cor <- as.numeric(res.cor$estimate)\r\n\r\n# variances\r\nvar.stock <- var(ret.stock, na.rm = TRUE)\r\nvar.market <- var(ret.market, na.rm = TRUE)\r\n\r\n# risk free rate (short term treasury bond rate, from central bank website)\r\nrf <- 0.17\r\n\r\nexc.market <- ret.market - rf/250 #Rm-Rf (excess market)\r\nexc.stock <- ret.stock - rf/250 #Ri-Rf (excess return)\r\n\r\nreg <- lm(exc.stock ~ exc.market)\r\nsummary(reg)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = exc.stock ~ exc.market)\r\n\r\nResiduals:\r\n      Min        1Q    Median        3Q       Max \r\n-0.086592 -0.009943 -0.000638  0.010110  0.150381 \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value            Pr(>|t|)    \r\n(Intercept) 0.0006139  0.0003326   1.846               0.065 .  \r\nexc.market  0.7223823  0.0204305  35.358 <0.0000000000000002 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 0.01794 on 2909 degrees of freedom\r\n  (151 observations deleted due to missingness)\r\nMultiple R-squared:  0.3006,    Adjusted R-squared:  0.3003 \r\nF-statistic:  1250 on 1 and 2909 DF,  p-value: < 0.00000000000000022\r\n\r\nreg$coefficients\r\n\r\n\r\n (Intercept)   exc.market \r\n0.0006139034 0.7223822894 \r\n\r\n# E[Rm] --> historical average of Rm, annualized\r\nErm <- mean(ret.market, na.rm = TRUE) * 250\r\n\r\n# E[Ri] <- Rf + Beta * (E[Rm] - Rf)\r\n\r\nbeta <- 0.6369378051\r\n\r\nri <- rf + beta * (Erm - rf)\r\n\r\n\r\n\r\n\\(\\beta\\) coefficient value is\r\n0.6369. Expected \\(r_{m}\\) will be\r\n0.1156. Risk free rate for Turkey is 17%, we keep it constant.\r\nWe are re-implementing the gordon growth model.\r\nwe calculate the dividend growth rate with the geometric mean.\r\n\r\n\r\ndata <- read_excel(\"ass_2.xlsx\", sheet = \"Sheet2\")\r\n\r\ndata <- data %>% \r\n  mutate(lag_div=shift(Dividend, 1, type= \"lag\"),\r\n         div_growth_rate= (Dividend-lag_div)/lag_div) %>% \r\n  select(c(-\"lag_div\")) \r\n\r\narithmetic_g <- mean(data$div_growth_rate, na.rm = TRUE)\r\n# geometric_g1 <- geometric.mean(data$div_growth_rate, na.rm = TRUE)\r\ngeometric_g <- 0.2355\r\n\r\n\r\n\r\nDividend growth rate (g) here is 0.2355.\r\nIf we apply the Gordon growth model (\\(V_{0}=\\frac{D_{0}*(1+g)}{(r_{i}-g)}\\)).\r\n\r\n\r\nD_0 <- 15.15\r\n\r\ng <- 0.2355\r\n\r\nri <- 0.1354\r\n\r\n\r\nV_0 <- (D_0 * ( 1+ g)) / (ri - g)\r\n\r\n\r\n\r\nHere the result is again a negative value because the dividend growth\r\nrate is greater than the reqired return. We will assume the opposite\r\ncase, namely r > g.\r\nThis time let’s assume \\(r_{i}\\) is\r\n25%. Because the value of g is 23% and the \\(r_{i}\\) value we choose must be greater\r\nthan g.\r\nFor 25%\r\n\r\n\r\nD_0 <- 15.15\r\n\r\ng <- 0.2355\r\n\r\nri <- 0.25\r\n\r\n\r\nV_0 <- (D_0 * ( 1+ g)) / (ri - g)\r\n\r\n\r\n\r\nThe resulting price is 1290,884.\r\nTWO-STAGE DIVIDEND DISCOUNT MODEL\r\nWe will now apply the two-stage dividend discount model.\r\nThe formula in this model is as follows.\r\n\\(V_{0}=\\sum_{t=1}^{n}\r\n\\frac{D_{0}\\left(1+g_{S}\\right)^{t}}{(1+r)^{t}}+\\frac{D_{0}\r\n\\times\\left(1+g_{S}\\right)^{n} \\times\\left(1+g_{L}\\right)}{(1+r)^{n}\r\n\\times\\left(r-g_{L}\\right)}\\)\r\nWe use dividend data from 2007 to 2019.\r\nThe last dividend price paid is 15.15 and divident growth rate is\r\n0.1723 (\\(g_{s}\\), that is, long\r\nterm).\r\nStep 1: Calculate the first four dividends:\r\nDo(1+gs) D1(1+gs) D2(1+gs) D3(1+gs) D4*(1+gs)\r\n\r\n\r\nD_0 <- 15.15\r\ng <- 0.1723\r\nri <- 0.1067\r\n\r\nD1 <- D_0*(1+g)\r\nD2 <- D1*(1+g)\r\nD3 <- D2*(1+g)\r\nD4 <- D3*(1+g)\r\n\r\n#Step 2: Calculate the Year 5 dividend:\r\n\r\nD5 <- D4*(1+ 0.08)\r\n\r\n#Step 3: Calculate the value of the constant growth dividends:\r\n\r\nV4= D5/(ri-0.08)\r\n\r\n\r\n\r\nWhere\r\nD1 is 17.76\r\nD2 is 20.82\r\nD3 is 24.40\r\nD4 is 28.61\r\nD5 is 30.90\r\nTherefore V4 is 1157.291\r\nIf we do it for \\(r_{i}\\) equals 20%\r\n\r\n\r\nD_0 <- 15.15\r\ng <- 0.1723\r\nri <- 0.20\r\n\r\nD1 <- D_0*(1+g)\r\nD2 <- D1*(1+g)\r\nD3 <- D2*(1+g)\r\nD4 <- D3*(1+g)\r\n\r\n#Step 2: Calculate the Year 5 dividend:\r\n\r\nD5 <- D4*(1+ 0.08)\r\n\r\n#Step 3: Calculate the value of the constant growth dividends:\r\n\r\nV4= D5/(ri-0.08)\r\n\r\nV_0 <- (D1/(1+ri)) + (D2/(1+ri)^2) + (D3/(1+ri)^3) + (D4/(1+ri)^4) +\r\n       (D5/(1+ri)^5) + (V4/(1+ri)^5) \r\n\r\n\r\n\r\nV4 becomes 257.5195 when \\(r_{i}\\)\r\nis 20%. V_0 is 173.093\r\nIf we do it for \\(r_{i}\\) equals 25%\r\n\r\n\r\nD_0 <- 15.15\r\ng <- 0.1723\r\nri <- 0.25\r\n\r\nD1 <- D_0*(1+g)\r\nD2 <- D1*(1+g)\r\nD3 <- D2*(1+g)\r\nD4 <- D3*(1+g)\r\n\r\n#Step 2: Calculate the Year 5 dividend:\r\n\r\nD5 <- D4*(1+ 0.08)\r\n\r\n#Step 3: Calculate the value of the constant growth dividends:\r\n\r\nV4= D5/(ri-0.08)\r\n\r\nV_0 <- (D1/(1+ri)) + (D2/(1+ri)^2) + (D3/(1+ri)^3) + (D4/(1+ri)^4) +\r\n       (D5/(1+ri)^5) + (V4/(1+ri)^5)\r\n\r\n\r\n\r\nV4 becomes 181.7785 when \\(r_{i}\\)\r\nis 25%. V_0 is 121.4414\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-26-equity-valuation/equity-valuation_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2022-08-26T20:43:05+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-07-ff93-en/",
    "title": "Portfolio Selection: Three Factor Model (Fama and French'93) vs Sharpe Ratio",
    "description": "In this study we will select a portfolio based on Fama and French's (1993) three-factor model study. Next, we will compare the sharpe ratio with the three factor model.",
    "author": [
      {
        "name": "Irem Dastan",
        "url": {}
      }
    ],
    "date": "2022-08-07",
    "categories": [
      "Portfolio Selection",
      "CAPM",
      "Risk-Return",
      "Market Microstructure"
    ],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(readxl)\r\nlibrary(PerformanceAnalytics)\r\nlibrary(kableExtra)\r\n\r\n\r\n\r\nPortfolio\r\nSelection: Three Factor Model (Fama and French’93) vs Sharpe Ratio\r\nThis time we will select a portfolio based on Fama and French’s\r\n(1993) three-factor model study. Next, we will compare the sharpe ratio\r\nwith the three factor model.\r\nThis model describes stock returns through three factors\r\nmarket risk,\r\nbetter performance of small-cap companies than large-cap\r\ncompanies, and\r\nhigh book-companies with low book value versus companies that\r\nperform better than the market.\r\nThe model argues that high-value and small-cap companies tend to\r\nconsistently outperform the general market.\r\nFor\r\nthose who want to examine this article of Fama and French (1993) in more\r\ndetail, click below.\r\nHere\r\nFama & French (1993) three factor model is as\r\nfollows:\r\n\\(\\mathrm{R}_{\\mathrm{it}}-\\mathrm{R}_{\\mathrm{ft}}=\\alpha_{\\mathrm{i}}+\\beta_{\\mathrm{i}}\\left(\\mathrm{R}_{\\mathrm{mt}}-\\mathrm{R}_{\\mathrm{ft}}\\right)+\\mathrm{s}_{\\mathrm{i}}\r\n\\mathrm{SMB}_{\\mathrm{t}}+\\mathrm{h}_{\\mathrm{i}}\r\n\\mathrm{HML}_{\\mathrm{t}}\\)\r\nwhere\r\n\\(R_{i,t}\\) : Return on asset i at\r\ntime t\r\n\\(R_{f,t}\\) : The value of the\r\nrisk-free rate at time t\r\n\\(R_{m,t}\\) : Return of the market\r\nportfolio at time t\r\n\\(\\alpha_{\\mathrm{i}}\\) : Model’s\r\npricing error\r\n\\(SMB_{t}\\) : The difference in\r\nreturn for portfolios with small and large market caps at time t.\r\n\\(HML_{t}\\) : The difference in\r\nreturn for portfolios with high and low MV/BV ratios at time t.\r\n\\(\\beta_{\\mathrm{i}}, s_{i}, h_{i}\\)\r\n: \\(\\beta\\) coefficients.\r\nMy dataset includes 88 stocks I bought from Reuters between 28 May\r\n2020 and 31 May 2022. Also, I used the “is yatirim” website for market\r\nvalue/book value data.\r\n\r\n\r\n\r\n#importing the data\r\n\r\nhist_price <- read_excel(\"7822/historical.xlsx\")\r\nnofna <- setNames(colSums(is.na(hist_price)), names(hist_price)) %>% \r\n  as.data.frame() %>% \r\n  rename(\"NofNA\"=1) %>% \r\n  filter(NofNA == 0) %>% \r\n  rownames_to_column(var = \"Ticker\")\r\n\r\nhist_price <- hist_price %>% \r\n  select(nofna$Ticker) %>% \r\n  arrange(DATE) %>% \r\n  mutate(DATE = as.Date(DATE)) %>% \r\n  dplyr::filter(DATE >= as.Date(\"2020-05-28\") & DATE <= as.Date(\"2022-05-31\")) %>% \r\n  mutate_at(vars(-DATE), function(x) lag((lead(x)-x)/x)) %>% \r\n  na.omit()\r\n\r\n# market value/book value are from isyatirim\r\nmv_bv <- read_excel(\"7822/temelfinansal.xlsx\") %>%\r\n  select(1,6,7) %>% \r\n  rename(\"Ticker\"=1,\"MVBV\"=2,\"Date\"=3) %>% \r\n  dplyr::filter(Ticker %in% nofna$Ticker)\r\n\r\nmv <- read_excel(\"7822/temelozet.xlsx\") %>%\r\n  select(1,5) %>% \r\n  rename(\"Ticker\"=1,\"MV\"=2) %>% \r\n  dplyr::filter(Ticker %in% nofna$Ticker)\r\n\r\nriskfree <- 0.17/nrow(hist_price) #risk free rate for Turkey\r\n\r\nMarketRet <- hist_price %>% \r\n  select(DATE,BIST100) %>% \r\n  mutate(BIST100 = BIST100 - riskfree)\r\n\r\n\r\n\r\nEquities are divided into two portfolios, small (S) and large (B),\r\naccording to the size of the firm. According to the MV/BV ratio, the\r\ncompanies are; It is divided into three portfolios,\r\nlow (L), medium (M), and high (H).\r\nPortfolios consisting of the intersection of these portfolios are as\r\nfollows:\r\nSL = This portfolio consists of stocks that\r\nare small for firm size and have the lowest MV/BV ratio in terms of\r\nMV/BV ratio.\r\nSM = This portfolio consists of stocks with\r\na MV/BV ratio that is small according to firm size and medium-sized in\r\nterms of MV/BV ratio.\r\nSH = This portfolio consists of stocks that\r\nare small for the size of the firm and have a high MV/BV ratio in terms\r\nof MV/BV ratio.\r\nBL = This portfolio consists of stocks with\r\na large MV/BV ratio and a low MV/BV ratio in terms of firm size.\r\nBM = This portfolio consists of stocks with\r\na large MV/BV ratio and a medium size MV/BV ratio in terms of firm\r\nsize.\r\nBH = This portfolio consists of stocks that\r\nare large for the size of the firm and have a high MV/BV ratio in terms\r\nof MV/BV ratio.\r\nHere we divide market value into two as small and big, and\r\nmarket value/book value into three as low, medium and high.\r\n\r\n\r\ndf <- mv %>% \r\n  left_join(mv_bv, by = \"Ticker\") %>% \r\n  mutate(\r\n    N_MVClass = ntile(MV,2),\r\n    N_MVBV = ntile(MVBV,3),\r\n    MVClass = case_when(\r\n      N_MVClass == 1 ~ \"S\",\r\n      N_MVClass == 2 ~ \"B\"\r\n    ),\r\n    MVBVClass = case_when(\r\n      N_MVBV == 1 ~ \"L\",\r\n      N_MVBV == 2 ~ \"M\",\r\n      N_MVBV == 3 ~ \"H\"\r\n    )\r\n  )\r\n\r\n\r\n\r\nWe combine them according to the 6 portfolios we created\r\nabove.\r\n\r\n\r\nportfolio_strategy <- df %>% \r\n  mutate(\r\n    MainClass = paste0(MVClass,MVBVClass)\r\n  )\r\n\r\n\r\n\r\nCalculation of SMB\r\n\r\n\r\ns_ticker <- df %>% \r\n  dplyr::filter(MVClass == \"S\") %>% \r\n  pull(Ticker)\r\n\r\ns_portfolio <- hist_price %>% \r\n  select(DATE,s_ticker)\r\n\r\nportfolio_s_return <- s_portfolio %>% \r\n  column_to_rownames(var = \"DATE\")\r\n\r\ns_weights <- 1/ncol(portfolio_s_return)\r\n\r\ns_return <- Return.portfolio(portfolio_s_return,\r\n                             weights = rep(s_weights,ncol(portfolio_s_return)))\r\n\r\nportfolio_s_return <- as.data.frame(s_return) %>% \r\n  rownames_to_column(var = \"DATE\") %>% \r\n  rename(\"RETURN_S\"=2)\r\n\r\n##\r\n\r\ndf_b <- df %>% \r\n  dplyr::filter(MVClass == \"B\") %>% \r\n  pull(Ticker)\r\n\r\nb_portfolio <- hist_price %>% \r\n  select(DATE,df_b) %>% \r\n  drop_na()\r\n\r\nportfolio_b_return <- b_portfolio %>% \r\n  column_to_rownames(var = \"DATE\")\r\n\r\nb_weights <- 1/ncol(portfolio_b_return)\r\n\r\nb_return <- Return.portfolio(portfolio_b_return,\r\n                             weights = rep(b_weights,ncol(portfolio_b_return)))\r\n\r\nportfolio_b_return <- as.data.frame(b_return) %>% \r\n  rownames_to_column(var = \"DATE\") %>% \r\n  rename(\"RETURN_B\"=2)\r\n\r\nsmb_return <- merge(portfolio_s_return,portfolio_b_return,by=\"DATE\") %>% \r\n  mutate(RETURN_SMB = (RETURN_S - RETURN_B),\r\n         DATE = as.Date(DATE)) %>% \r\n  select(DATE,RETURN_SMB)\r\n\r\n\r\n\r\nCalculation of HML\r\n\r\n\r\ndf_h <- df %>% \r\n  dplyr::filter(MVBVClass == \"H\") %>% \r\n  pull(Ticker)\r\n\r\nh_portfolio <- hist_price %>% \r\n  select(DATE,df_h) %>% \r\n  drop_na()\r\n\r\nportfolio_h_return <- h_portfolio %>% \r\n  column_to_rownames(var = \"DATE\")\r\n\r\nh_weights <- 1/ncol(portfolio_h_return)\r\n\r\nh_return <- Return.portfolio(portfolio_h_return,\r\n                             weights = rep(h_weights,ncol(portfolio_h_return)))\r\n\r\nportfolio_h_return <- as.data.frame(h_return) %>% \r\n  rownames_to_column(var = \"DATE\") %>% \r\n  rename(\"RETURN_H\"=2)\r\n\r\n##\r\n\r\ndf_l <- df %>% \r\n  dplyr::filter(MVBVClass == \"L\") %>% \r\n  pull(Ticker)\r\n\r\nl_portfolio <- hist_price %>% \r\n  select(DATE,df_l) %>% \r\n  drop_na()\r\n\r\nportfolio_l_return <- l_portfolio %>% \r\n  column_to_rownames(var = \"DATE\")\r\n\r\nl_weights <- 1/ncol(portfolio_l_return)\r\n\r\nl_return <- Return.portfolio(portfolio_l_return,\r\n                             weights = rep(l_weights,ncol(portfolio_l_return)))\r\n\r\nportfolio_l_return <- as.data.frame(l_return) %>% \r\n  rownames_to_column(var = \"DATE\") %>% \r\n  rename(\"RETURN_L\"=2)\r\n\r\nhml_return <- merge(portfolio_h_return,portfolio_l_return,by=\"DATE\") %>% \r\n  mutate(RETURN_HML = (RETURN_H - RETURN_L),\r\n         DATE = as.Date(DATE)) %>% \r\n  select(DATE,RETURN_HML)\r\n\r\n\r\n\r\n\r\n\r\nsixportfolios <- data.frame()\r\nstrategies <- c(\"SL\",\"SM\",\"SH\",\"BL\",\"BM\",\"BH\")\r\n\r\nfor(s in 1:length(strategies)){\r\n  \r\n  portfolio_strategy_ticker <- portfolio_strategy %>% \r\n    filter(MainClass == strategies[s]) %>% \r\n    pull(Ticker)\r\n  \r\n  portfolio_strategy_return <- hist_price %>% \r\n    select(DATE,portfolio_strategy_ticker)\r\n  \r\n  portfolio_strategy_return <- portfolio_strategy_return %>% \r\n    column_to_rownames(var = \"DATE\")\r\n  \r\n  strategy_weights <- 1/ncol(portfolio_strategy_return)\r\n  \r\n  strategy_return <- Return.portfolio(portfolio_strategy_return,\r\n                                      weights = rep(strategy_weights,\r\n                                                    ncol(portfolio_strategy_return)))\r\n  \r\n  #portfolio_strategy_return$DATE <- index(strategy_return)\r\n  portfolio_strategy_return$RETURN <- as.numeric(strategy_return$portfolio.returns)\r\n  portfolio_strategy_return$TYPE <- strategies[s]\r\n  \r\n  portfolio_strategy_return <- as.data.frame(portfolio_strategy_return) %>% \r\n    rownames_to_column(var = \"DATE\") %>% \r\n    rename(\"RETURN_X\"=2) %>% \r\n    mutate(RETURN_X = RETURN_X - riskfree, DATE = as.Date(DATE)) %>% \r\n    select(DATE,RETURN_X,TYPE)\r\n  \r\n  sixportfolios <- sixportfolios %>% bind_rows(portfolio_strategy_return)\r\n  \r\n  if(s == 6){\r\n    \r\n    sixportfolios$RETURN_X <- sixportfolios$RETURN_X - riskfree\r\n      }\r\n  }\r\n\r\n\r\n\r\nIn this section, we perform regression analysis for 6\r\nportfolios.\r\n\\(H_{0}\\): The alpha coefficient\r\nestimated in the time series regressions applied to test whether the\r\nFama and French Three-Factor Asset Pricing Model is valid in Borsa\r\nIstanbul is not different from zero.\r\n\\(H_1\\): The alpha coefficient\r\nestimated in the time series regressions applied to test whether the\r\nFama and French Three-Factor Asset Pricing Model is valid in Borsa\r\nIstanbul is different from zero.\r\nFor \\(\\alpha\\) we take portfolios\r\nwhere we cannot reject \\(H_{0}\\) at the\r\n0.05 level.\r\n\r\n\r\nmodeloutput <- data.frame()\r\n\r\nfor(k in 1:length(strategies)){\r\n  \r\n  regressionDF <- sixportfolios %>% \r\n    dplyr::filter(TYPE == strategies[k]) %>% \r\n    select(DATE,RETURN_X,-TYPE) %>% \r\n    left_join(MarketRet, by = \"DATE\") %>% \r\n    left_join(smb_return, by = \"DATE\") %>% \r\n    left_join(hml_return, by = \"DATE\")\r\n  \r\n  model <- lm(RETURN_X ~ BIST100 + RETURN_SMB + RETURN_HML, data = regressionDF)\r\n  \r\n  tbloutput <- data.frame(\r\n    alpha = as.numeric(summary(model)$coefficients[,4][1]),\r\n    beta = as.numeric(summary(model)$coefficients[,4][2]),\r\n    SMB_param = as.numeric(summary(model)$coefficients[,4][3]),\r\n    HML_param = as.numeric(summary(model)$coefficients[,4][4]),\r\n    TYPE = strategies[k]\r\n  )\r\n  \r\n  modeloutput <- modeloutput %>% bind_rows(tbloutput)\r\n  \r\n  if(k == length(strategies)){\r\n    \r\n    modeloutput <- modeloutput %>% \r\n      pivot_longer(!TYPE, names_to = \"Parameters\", values_to = \"p_values\") %>% \r\n      arrange(TYPE) %>% \r\n      mutate(Result = ifelse(p_values <= 0.05, \"<= 0.05\",\"> 0.05\")) %>% \r\n      select(-p_values) %>% \r\n      pivot_wider(names_from = \"Parameters\", values_from = \"Result\")\r\n    \r\n  }\r\n  \r\n}\r\n\r\nmodeloutput %>% \r\n  kbl() %>% \r\n  kable_styling()\r\n\r\n\r\n\r\nTYPE\r\n\r\n\r\nalpha\r\n\r\n\r\nbeta\r\n\r\n\r\nSMB_param\r\n\r\n\r\nHML_param\r\n\r\n\r\nBH\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n> 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\nBL\r\n\r\n\r\n> 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n> 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\nBM\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n> 0.05\r\n\r\n\r\n> 0.05\r\n\r\n\r\nSH\r\n\r\n\r\n> 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n> 0.05\r\n\r\n\r\nSL\r\n\r\n\r\n> 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n> 0.05\r\n\r\n\r\nSM\r\n\r\n\r\n> 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n<= 0.05\r\n\r\n\r\n> 0.05\r\n\r\n\r\n\r\n\r\nwhichisthebest <- modeloutput %>% \r\n  dplyr::filter(alpha == \"<= 0.05\") %>% \r\n  pull(TYPE)\r\n\r\ncomparedf <- sixportfolios %>% \r\n  dplyr::filter(TYPE %in% whichisthebest) %>% \r\n  group_by(TYPE) %>% \r\n  summarise(\r\n    ExpectedReturn = mean(RETURN_X),\r\n    Risk = sd(RETURN_X),\r\n    Sharpe = (ExpectedReturn - riskfree) / Risk\r\n  ) %>% \r\n  arrange(desc(Sharpe)) %>% \r\n  slice(1) %>% \r\n  pull(TYPE)\r\n\r\n\r\n\r\nNow, we need to determine the stocks that we will sell short\r\naccording to the portfolio we have created. In determining this, we get\r\nhelp from the regression line.\r\nAccordingly, the parts whose price is above the 95% band are\r\ndetermined as “Sell Zone”. This is known as the\r\noverbought zone. Short selling is based on the fact that stocks will go\r\ndown. For this reason, the shares in these regions were sold short.\r\n\r\n\r\nportfolio_strategy_x_ticker <- portfolio_strategy %>% \r\n    filter(MainClass == comparedf) %>% \r\n    pull(Ticker)\r\n\r\nshortselling <- read_excel(\"7822/historical.xlsx\") %>% \r\n  arrange(DATE) %>% \r\n  mutate(DATE = as.Date(DATE)) %>% \r\n  dplyr::filter(DATE >= as.Date(\"2020-05-28\") & DATE <= as.Date(\"2022-05-31\")) %>% \r\n  select(DATE,portfolio_strategy_x_ticker) %>% \r\n  pivot_longer(!DATE, names_to = \"Ticker\", values_to = \"Price\") %>% \r\n  arrange(Ticker) %>% \r\n  mutate(t = seq(1,nrow(.),1))\r\n\r\nfor(i in 1:length(portfolio_strategy_x_ticker)){\r\n  \r\n  filteredStock <- portfolio_strategy_x_ticker[i]\r\n  thestock <- shortselling %>% \r\n    filter(Ticker == filteredStock)\r\n  \r\n  model2 <- lm(Price ~ t, data = thestock)\r\n  summary(model2)\r\n  \r\n  thestock$Fitted <- model2$fitted.values\r\n  thestock$lwr95 <- predict(model2, interval = \"predict\", level = 0.95)[,2]\r\n  thestock$upr95 <- predict(model2, interval = \"predict\", level = 0.95)[,3]\r\n  \r\n  g <- ggplot(thestock) +\r\n    geom_line(aes(x = t, y = Price)) +\r\n    geom_line(aes(x = t, y = Fitted)) +\r\n    geom_line(aes(x = t, y = lwr95), linetype = \"dashed\", color = \"red\") +\r\n    geom_line(aes(x = t, y = upr95), linetype = \"dashed\", color = \"red\") +\r\n    theme_minimal() +\r\n    theme(axis.title = element_blank()) +\r\n    labs(title = paste0(portfolio_strategy_x_ticker[i]))\r\n  \r\n  ggsave(paste0(i,\".jpg\"))\r\n  \r\n}\r\n\r\n\r\n\r\nAccording to this analysis we made;\r\nShort Selling: AKSA, ALARK, DOAS, HEKTS, OYAKC,\r\nSASA, TUPRS\r\nBuy Selling: BIMAS, BRISA, FROTO, GUBRF, TOASO,\r\nTTKOM, TTRAK, VESBE\r\n\r\n\r\nshort_selling <- c(\"AKSA\", \"ALARK\", \"DOAS\", \"HEKTS\", \"OYAKC\", \"SASA\", \"TUPRS\")\r\nbuy_selling <- c(\"BIMAS\", \"BRISA\", \"FROTO\", \"GUBRF\", \"TOASO\", \"TTKOM\", \"TTRAK\", \"VESBE\")\r\n\r\nmaster <- hist_price %>% \r\n  select(DATE,portfolio_strategy_x_ticker) %>% \r\n  drop_na() %>% \r\n  pivot_longer(!DATE, names_to = \"Ticker\", values_to = \"Return\") %>% \r\n  arrange(Ticker) %>% \r\n  mutate(\r\n    \"NewReturn\" = case_when(\r\n      Ticker %in% short_selling ~ Return * -1,\r\n      Ticker %in% buy_selling ~ Return * 1\r\n    )\r\n  )\r\n\r\n\r\n\r\n\r\n\r\nnewReturndf <- master %>% \r\n  select(-Return) %>% \r\n  pivot_wider(names_from = \"Ticker\", values_from = \"NewReturn\") %>% \r\n  column_to_rownames(var = \"DATE\")\r\n\r\nnew_weights <- rep(1/nrow(newReturndf),ncol(newReturndf))\r\n\r\nnew_portfolio_daily_returns <- Return.portfolio(newReturndf, weights = new_weights)\r\nnew_expectedReturn <- mean(new_portfolio_daily_returns$portfolio.returns)\r\nnew_risk <- sd(new_portfolio_daily_returns$portfolio.returns)\r\nsharpe_ratio <- round(SharpeRatio(new_portfolio_daily_returns, Rf = riskfree), 4) %>% .[[1]]\r\n\r\nticker_summary <- newReturndf %>% \r\n  rownames_to_column(var = \"DATE\") %>% \r\n  `row.names<-`(NULL) %>% \r\n  pivot_longer(!DATE, names_to = \"Ticker\", values_to = \"NewReturn\") %>% \r\n  arrange(Ticker) %>% \r\n  group_by(Ticker) %>% \r\n  summarise(\r\n    Mean = mean(NewReturn),\r\n    Sd = sd(NewReturn),\r\n    Sharpe = (Mean - riskfree) / Sd\r\n  )\r\n\r\nggplot(ticker_summary, aes(x = Mean, y = Sd, color = Ticker)) +\r\n  geom_point() +\r\n  ggrepel::geom_text_repel(aes(label = Ticker)) +\r\n  theme_minimal() +\r\n  theme(legend.position = \"none\") +\r\n  labs(x = \"Risk\", y = \"Expected Return\")\r\n\r\n\r\n\r\n\r\nIn the graph, we see the values of the portfolio we created in terms\r\nof expected return and risk. The risks of GUBRF, FROTO, BRISA, TTRAK,\r\nTOASO and VESBE stocks are very close to each other. However, the stock\r\nwith the highest return at the same risk level is GUBRF. On the other\r\nhand, we can say that DOAS, SASA, HEKTS and AKSA have almost the same\r\nrisk level. However, the stock with the highest expected return is DOAS.\r\nAs a result, when we look at it from a risk-return point of view, DOAS\r\nseems to be the asset that we will provide the most return on.\r\n\r\n\r\nlastPortfolio_summary <- newReturndf %>% \r\n  rownames_to_column(var = \"DATE\") %>% \r\n  `row.names<-`(NULL) %>% \r\n  pivot_longer(!DATE, names_to = \"Ticker\", values_to = \"NewReturn\") %>% \r\n  arrange(Ticker) %>% \r\n  summarise(\r\n    ExpectedReturn = mean(NewReturn),\r\n    Risk = sd(NewReturn),\r\n    Sharpe = (ExpectedReturn - riskfree) / Risk\r\n  ) %>% \r\n  bind_rows(\r\n    data.frame(\r\n      ExpectedReturn = 0.001,\r\n      Risk = 0.02,\r\n      Sharpe = 0.031\r\n    )\r\n  ) %>% \r\n  mutate(\"PortfolioType\" = c(\"Last\",\"Previous\")) %>% \r\n  pivot_longer(!PortfolioType, names_to = \"Type\", values_to = \"Values\")\r\n\r\nggplot(lastPortfolio_summary, aes(x = Type, y = Values, fill = PortfolioType)) +\r\n  geom_bar(stat = \"identity\", position = position_dodge()) +\r\n  geom_text(aes(label = round(Values, digits = 3)),\r\n            position = position_dodge(width = 0.9), vjust = -0.2) +\r\n  theme_minimal() +\r\n  theme(legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.title = element_text(hjust = 0.5),\r\n        axis.title = element_blank()) +\r\n  scale_fill_manual(values = c(\"light blue\",\"pink\")) +\r\n  labs(title = \"Previous Portfolio vs Current Portfolio\")\r\n\r\n\r\n\r\n\r\nIn the chart we see the comparison of the two portfolios. Both are\r\nsimilar in terms of expected return. Although the risks seem to be close\r\nto each other, the risk of the portfolio in the previous project is less\r\nat 0.009 level.\r\nIf we compare the two portfolios in terms of Sharpe\r\nratio,\r\nIn the previous project, the portfolio’s sharpe ratio resulted in a\r\nvalue of 0.031. In the portfolio we created according to the\r\nThree Factor Model used by Fama & French (1993), the Sharpe\r\nratio was negative with -0.026 value. A negative Sharpe ratio\r\nmeans that the portfolio’s return is actually negative.\r\nThe high Sharpe performance ratio of the portfolio increases the\r\nprobability of choosing that portfolio.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-07-ff93-en/ff93-en_files/figure-html5/unnamed-chunk-12-1.png",
    "last_modified": "2022-08-07T21:49:51+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-16-portfolio-selection-en/",
    "title": "Optimum Portfolio Selection",
    "description": "We are gonna create the best portfolio with 10 stocks selected from BIST.",
    "author": [
      {
        "name": "Irem Dastan",
        "url": {}
      }
    ],
    "date": "2022-05-16",
    "categories": [
      "Finance",
      "Portfolio Selection"
    ],
    "contents": "\r\n\r\n\r\nlibrary(readxl);library(tidyverse);library(openxlsx);\r\nlibrary(data.table);library(mice);library(knitr);library(kableExtra);\r\nlibrary(quantmod);library(TTR);library(readxl);library(timeSeries);\r\nlibrary(fPortfolio);library(tseries);library(PerformanceAnalytics)\r\n\r\n\r\n\r\nIn a portfolio, it is necessary to consider the risk as well as the\r\nreturn. The risk of a high-yielding asset can be very high, and if you\r\ndid not make the right choice, you are very likely to lose. For example,\r\nlet’s say an asset X has a return of 2.5% and a variance of 4%. On the\r\nother hand, an asset Y has the same risk, but its return is 3.5%. How\r\ndoes ? Let’s see in the graph below.\r\n\r\n\r\n\r\nIf we compare the points A’, B’ and C’ with the points A, B, C on the\r\ngraph; We see that A and A’ have the same risk, but A’s provides a\r\nhigher return. The same is true for other points.\r\n! The investor must be desire to act according to efficient\r\nfrontier.\r\nFor more detailed information on the subject, you can read the paper by\r\nMarkowitz, H. (1952).\r\nLet’s apply this to stocks.\r\nFirstly, I selected 10 stocks between 31 December 2019 and 30\r\nDecember 2021. The stocks I chose are as follows;\r\nAKBNK, SAHOL, TUPRS, THYAO, KCHOL, SISE, TAVHL, TCELL, HALKB,\r\nTTKOM\r\nImporting the data\r\n\r\n\r\ndata <- read_excel(\"data.xlsx\") # You can access the data on my GitHub.\r\ndata <- na.omit(data) \r\n\r\n#I'm checking to see if there are any missing observations.\r\nmd.pattern(data)\r\n\r\n\r\n /\\     /\\\r\n{  `---'  }\r\n{  O   O  }\r\n==>  V <==  No need for mice. This data set is completely observed.\r\n \\  \\|/  /\r\n  `-----'\r\n\r\n     Ticker Date Close  \r\n5010      1    1     1 0\r\n          0    0     0 0\r\n\r\nCalculating the Returns\r\n\r\n\r\ndata <- data %>% \r\n  arrange(Ticker) %>%\r\n  group_by(Ticker) %>%\r\n  mutate(lagClose=shift(Close, 1, type= \"lag\"),\r\n         perReturn= (Close-lagClose)/lagClose,\r\n         logReturn= log(Close/lagClose)) %>%\r\n ungroup()\r\n\r\nggplot(data, aes(x=Date, y=perReturn, group= Ticker)) +\r\n  geom_line(color=\"#80d7cc\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n  plot.title = element_text(face = \"italic\", hjust = 0.5)) +\r\n  geom_hline(yintercept = 0) +\r\n  ggtitle(\"Per Return\")\r\n\r\n\r\n\r\n\r\nSummary Statistics\r\n\r\n\r\n#Transpose\r\nt_data <- data %>%\r\n  select(Ticker,Date,perReturn) %>% \r\n  pivot_wider(names_from = \"Ticker\", values_from = \"perReturn\") %>% \r\n  slice(-1)\r\n\r\ndat <- t_data %>% \r\n  column_to_rownames(var = \"Date\")\r\n\r\ndat_cor <- dat %>% \r\n  cor()\r\n\r\n\r\n\r\nThere must be a negative relationship between the correlations.\r\nBecause the investor has to pass the loss from one stock to the profit\r\nfrom the other. If the correlation is zero (0), it means that there is\r\nno relationship between them.\r\n\r\n\r\ndat_vcov <- dat %>% \r\n  cov(dat) %>% \r\n  as.data.frame() %>% \r\n  mutate_all(.funs = function(x) round(x, digits = 4))\r\n\r\ndat_summary <- dat %>% \r\n  pivot_longer(everything()) %>% \r\n  arrange(name) %>% \r\n  group_by(name) %>%\r\n  summarise_at(vars(value), list(Min = min, Mean = mean, Max = max, Sd = sd))\r\n\r\n\r\n# For Turkey Risk Free rate (Rf): 17,7%\r\nrf <- 0.17/250  # Daily risk free rate \r\n\r\ndat_summary <- dat_summary %>% \r\n  mutate(\r\n    Sharpe = (Mean - rf) / Sd\r\n  ) %>% \r\n  arrange(Sharpe)\r\n\r\nggplot(dat_summary, aes(x= Sd, y= Mean, color = name, size = Sharpe)) +\r\n  geom_point(alpha = .5) + \r\n  ggrepel::geom_text_repel(aes(label = paste0(name,\" (\",round(Sharpe, digits = 3),\")\"))) +\r\n  theme_minimal() +\r\n  theme(legend.position = \"none\") +\r\n  labs(x = \"Risk\", y = \"Expected Return\") \r\n\r\n\r\n\r\n\r\nThe size of the points here is according to the sharpe ratio.\r\nA high Sharpe ratio means that the portfolio created is resistant to\r\nrisks, and a low one means that the portfolio created is open to risks.\r\nAmong the 10 stocks I chose, HALKB is the most open to risk.\r\nKCHOL and THYAO have relatively close risks to each other. TCELL has\r\nsimilar risks in SAHOL and TTKOM. SISE is the most risk-resistant stock\r\nwith the highest ratio. If we choose the best 2 stocks;\r\n1st SISE\r\n2nd. It is THYAO\r\nLet’s\r\ncreate two stock portfolios and choose a portfolio among them.\r\n\r\n\r\nsharpe <- NULL\r\nstock1 <- NULL\r\nstock2 <- NULL\r\nweights <- seq(0.1,0.9,0.1)\r\n\r\nfor (j in 1:length(colnames(dat))) { \r\n  for (i in 1:length(colnames(dat))) { \r\n    \r\n    if(i != j) {\r\n      x <- dat[,j] \r\n      y <- dat[,i] \r\n      \r\n      for (w.x in weights) { \r\n        \r\n        w.y <- 1 - w.x\r\n        \r\n        p_Return <- mean(x) * w.x + mean(y) * w.y\r\n        p_Risk <- (var(x) * w.x^2 + var(y) * w.y^2 + 2 * w.x * w.y * cov(x,y))^0.5\r\n        \r\n        temp.sharp <- (p_Return - rf) /  p_Risk\r\n        \r\n        sharpe <- c(sharpe, temp.sharp)\r\n        stock1 <- c(stock1, colnames(dat)[j])\r\n        stock2 <- c(stock2, colnames(dat)[i])\r\n        \r\n        rm(temp.sharp, p_Return, p_Risk, w.stock2)\r\n      }\r\n      rm(x,y)\r\n    }\r\n  }\r\n}\r\n\r\n\r\nweight_1 <- rep(weights,length(sharpe)/length(weights))\r\nsharpe.result <- data.frame(cbind(stock1,weight_1,stock2,sharpe))\r\nsharpe.result$sharpe <- as.numeric(as.character(sharpe.result$sharpe))\r\n\r\nsharpe.result <- sharpe.result[order(sharpe.result$sharpe, decreasing = TRUE),]\r\n\r\n\r\n# We've added a Risk and Return column below.\r\nsharpe.result$Return <- NA\r\nsharpe.result$Risk <- NA\r\n\r\nfor(i in 1:nrow(sharpe.result)){\r\n  \r\n  stock_1 <- sharpe.result[i,1]\r\n  stock_2 <- sharpe.result[i,3]\r\n  \r\n  stock_1_ret <- dat[[stock_1]]\r\n  stock_2_ret <- dat[[stock_2]]\r\n\r\n  stock_1_w <- as.numeric(sharpe.result[i,2])\r\n  stock_2_w <- 1 - stock_1_w\r\n\r\n  sharpe.result$Return[i] <- mean(stock_1_ret) * stock_1_w + mean(stock_2_ret) * stock_2_w\r\n  \r\n  sharpe.result$Risk[i] <- (var(stock_1_ret) * stock_1_w^2 + var(stock_2_ret) * stock_2_w^2 + 2 * \r\n                              stock_1_w * stock_2_w * cov(stock_1_ret,stock_2_ret))^0.5\r\n}\r\n\r\n\r\nnew_plot_df <- sharpe.result %>% \r\n  select(Return,Risk) %>% \r\n  bind_rows(\r\n    data.frame(\r\n      Return = dat_summary$Mean,\r\n      Risk = dat_summary$Sd\r\n    )\r\n  ) %>% \r\n  mutate(\r\n    colgr = c(rep(\"2 Stocks Portfolios\",810),rep(\"Single Stock Portfolio\",10))\r\n  )\r\n\r\n\r\n\r\nLet’s\r\nshow it in a risk-return graph where we compare portfolios of two stocks\r\nand portfolios of single stocks.\r\n\r\n\r\nggplot(new_plot_df, aes(x = Risk, y = Return, color = colgr)) +\r\n  geom_point() +\r\n  theme_minimal() +\r\n  theme(legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.title = element_text(face = \"italic\", hjust = 0.5)) +\r\n  labs(x = \"Risk\", y = \"Expected Return\") +\r\n  scale_color_manual(values = c(\"gray\",\"red\")) +\r\n  labs(title = \"Two Stocks Portfolios vs Single Stock Portfolio\") \r\n\r\n\r\n\r\n\r\nLet’s determine the\r\noptimal portfolio with:\r\n10 assets\r\n\\(W_{i} ≥ 0\\)\r\n\r\n\r\nstock10 <- data.frame(\r\n  matrix(data = \"\", nrow = 1, ncol = 10)\r\n) %>% \r\n  `colnames<-`(names(dat))\r\n\r\nfor(i in 1:100){  #Here, we weighed it 100 times differently.\r\n  \r\n  rnd <- wakefield::probs(10)\r\n  \r\n  for(j in 1:ncol(stock10)){\r\n    \r\n    stock10[i,j] <- rnd[j]\r\n    \r\n  }\r\n  \r\n}\r\n\r\nstock10 <- stock10 %>% \r\n  mutate_if(is.character, as.numeric) %>% \r\n  mutate_all(function(x) round(x, digits = 2)) %>% \r\n  distinct() %>% \r\n  mutate(ExpectedReturn = \"\",\r\n         Risk = \"\",\r\n         SharpeRatio = \"\")\r\n\r\nfor(k in 1:nrow(stock10)){\r\n  \r\n  portfolio_daily_returns <- Return.portfolio(dat, weights = as.numeric(stock10[k,c(1:10)]))\r\n  expectedReturn <- mean(portfolio_daily_returns$portfolio.returns)\r\n  risk <- sd(portfolio_daily_returns$portfolio.returns)\r\n  \r\n  sharpe_ratio <- round(\r\n  SharpeRatio(portfolio_daily_returns, Rf = 0.177/250), 4\r\n) %>% \r\n    .[[1]]\r\n  \r\n  stock10[k,11] <- expectedReturn\r\n  stock10[k,12] <- risk\r\n  stock10[k,13] <- sharpe_ratio\r\n  \r\n}\r\n\r\nstock10 <- stock10 %>% \r\n  mutate_if(is.character,as.numeric) %>% \r\n  mutate(MaxReturnPortfolio = ifelse(ExpectedReturn == max(ExpectedReturn),\"MaxReturn\",\"Others\"))\r\n\r\nggplot(stock10, aes(x = Risk, y = ExpectedReturn, color = MaxReturnPortfolio)) +\r\n  geom_point() +\r\n  theme_minimal() +\r\n  theme(legend.title = element_blank()) +\r\n  scale_color_manual(values = c(\"red\",\"gray\"))\r\n\r\n\r\n\r\nmyPortfolio <- stock10 %>% \r\n  dplyr::filter(MaxReturnPortfolio == \"MaxReturn\")\r\n\r\n\r\n\r\nThe red dot here is the best portfolio.\r\n\r\n\r\nAKBNK\r\n\r\n\r\nHALKB\r\n\r\n\r\nKCHOL\r\n\r\n\r\nSAHOL\r\n\r\n\r\nSISE\r\n\r\n\r\nTAVHL\r\n\r\n\r\nTCELL\r\n\r\n\r\nTHYAO\r\n\r\n\r\nTTKOM\r\n\r\n\r\nTUPRS\r\n\r\n\r\n0.11\r\n\r\n\r\n0.04\r\n\r\n\r\n0\r\n\r\n\r\n0.03\r\n\r\n\r\n0.22\r\n\r\n\r\n0.11\r\n\r\n\r\n0.11\r\n\r\n\r\n0.15\r\n\r\n\r\n0.11\r\n\r\n\r\n0.11\r\n\r\n\r\nExpectedReturn\r\n\r\n\r\nRisk\r\n\r\n\r\nSharpeRatio\r\n\r\n\r\n0.0010413\r\n\r\n\r\n0.0187875\r\n\r\n\r\n0.0177\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-16-portfolio-selection-en/img1.jpg",
    "last_modified": "2022-05-16T22:54:11+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-08-hft-en/",
    "title": "Investigating High-Frequency Trading (HFT) Around the Extreme Price Movements in Borsa Istanbul",
    "description": "In this study, I analyzed the existence of high-frequency trading (HFT) in Borsa Istanbul. My focus is it's the behavior and market share of high-frequency trading during extreme price movements (EPM).",
    "author": [
      {
        "name": "Irem Dastan",
        "url": {}
      }
    ],
    "date": "2022-05-08",
    "categories": [
      "Finance",
      "Market Microstructure"
    ],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(knitr)\r\nlibrary(kableExtra)\r\nlibrary(ggalt)\r\nlibrary(lubridate)\r\nlibrary(stargazer)\r\nlibrary(fastDummies)\r\n\r\ndata <- read.csv(\"data.csv\") #You can access the data on Github.\r\nnames(data)[1] <- \"stock\" \r\n\r\n\r\n\r\nIn this study, I analyzed the existence of high-frequency trading\r\n(HFT) in Borsa Istanbul. My focus is it’s the behavior and market share\r\nof high-frequency trading during extreme price movements (EPM).\r\nFully automated exchanges have increased the number of transactions\r\nin the market and enabled intermediaries to expand their use of\r\ntechnology. Trading behind software based on the ability to process and\r\nreact quickly to the trading flow of data, to the flow of market\r\ninformation has made it possible to carry out a large number of trading\r\nin a short time. However, there are still problems with speed in\r\nfinancial markets, using data to invest or to enter trades quickly. For\r\nthis reason, there is a speed race in which the fastest actors compete\r\nwith each other in financial markets. Thus, the markets are now\r\ndominated by computer algorithms, not by buying and selling tradings\r\nmade by humans.\r\nHFT; It is a type of trading that can be defined with thousands of\r\norder submissions, high order cancellations and intraday marginal profit\r\ntarget, keeping positions in seconds or milliseconds in fractions of a\r\nsecond. Briefly; “HFT leverages the technological capability of sending\r\nlarge numbers of orders at low millisecond delays” (Ersan and Ekinci,\r\n2016).\r\nAs HFT algorithms compete with each other, they face two\r\nchallenges:\r\nThey receive large amounts of data every microsecond.\r\nThey must be able to act very quickly on the observed data,\r\nbecause the profitability of the signals they observe decreases very\r\nquickly.\r\nThe dominant role played by HFT firms in providing liquidity and\r\nprice arbitrage in the market directly affects the market share of\r\ntrading areas. Its participation in arbitrages is obtained from the\r\nprice differences of the shares traded in more than one market, by\r\nmaking profit from small price differences with short-term trading and\r\nhigh volumes.\r\nBISTECH platform, which was put into use in the Equity Market on\r\nNovember 30, 2015, allowed the inclusion of HFT. HFT share in Borsa\r\nIstanbul is not as developed as the USA and European countries.\r\nThe difference between HFT and AT (Algorithmic Trading); AT is more\r\ncomprehensive and HFT is a subset of AT. AT is a structure that provides\r\ntrading with conditions defined in the computer environment, while HFT\r\nevaluates the opportunities that occur in very small seconds. In short,\r\nHFT is a variant of AT.\r\n\r\n\r\n\r\nStocks listed in BIST30 index.\r\n\r\n\r\n\r\n16-month period from December 2015 to March 2017, 339 trading\r\ndays.\r\n\r\n\r\n\r\nObtaining the daily versions of the variables obtained from the\r\nintraday order-trading books from the study of Ekinci and Ersan\r\n(2020).\r\nVariables in the study; HFT total, HFT trading sides, HFT trading\r\ndifference (HFT imbalance). Control variables; trading volume, liquidity\r\nand volatility. The dummy variables, which are the main independent\r\nvariables, are; extreme positive price movements (shares and days with\r\nreturns of 2% and more than 5%), and extreme negative price movements\r\n(stocks and days with returns below -2% and -5%).\r\nI analyze in three stages.\r\nBased on stock and return range\r\nT-test\r\nRegression analysis\r\nCalculating the HFT\r\nFirst of all, some orders are marked as HFT orders in the data. We do\r\nthis in two stages.\r\nFirst, orders with at least two messages (order submission,\r\nchange, cancellation) in 1 second or less.\r\nLatter, we determine it as any message of the HFT orders\r\ndetermined in the 1st stage, as other orders of the same stock that come\r\nin the same second and in the same size.\r\n\\(HFT\\ ratio_{i,t}=\\frac{Electronic\\\r\nmessage_{i,t}^{HFT}}{Electronic\\ message_{all^{HFT}}}\\)\r\n\\(Liquidity_{i,t}= \\sum_{j=1}^{N}\r\nVolume_{i,j,t}*(\\frac{Duration_{i,j,t}}{Duration_{total}})\\)\r\nAnalyzes\r\nStatistics of\r\nVariables in Daily Return Ranges\r\n\r\n\r\ntable1 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > -0.05 & return <= -0.02 ~ \"between -5% and -2%\",\r\n      return > -0.02 & return <= 0.02 ~ \"between -2% and 2%\",\r\n      return > 0.02 & return <= 0.05 ~ \"between 2% and 5%\",\r\n      return > 0.05 ~ \"above 5%\"\r\n    )\r\n  ) %>% \r\n  group_by(return_type) %>% \r\n  summarise(\r\n    avg_volatility = mean(volatility),\r\n    sd_volatility = sd(volatility),\r\n    avg_liquidity = mean(liquidity),\r\n    sd_liquidity = sd(liquidity),\r\n    avg_hft_buy = mean(hft_buy),\r\n    sd_hft_buy = sd(hft_buy),\r\n    avg_hft_sell = mean(hft_sell),\r\n    sd_hft_sell = sd(hft_sell),\r\n    avg_hft = mean(hft),\r\n    sd_hft = sd(hft),\r\n    avg_return = mean(return),\r\n    sd_return = sd(return),\r\n    avg_bist30_return = mean(bist30_return),\r\n    sd_bist30_return = sd(bist30_return),\r\n    avg_extra_ret_market = mean(extra_ret_market),\r\n    sd_extra_ret_market = sd(extra_ret_market),\r\n    avg_volume = mean(volume),\r\n    sd_volume = sd(volume)\r\n  ) %>% \r\n  mutate(\r\n    return_type = factor(\r\n      return_type, levels = c(\"below -5%\",\r\n                              \"between -5% and -2%\",\r\n                              \"between -2% and 2%\",\r\n                              \"between 2% and 5%\",\r\n                              \"above 5%\")\r\n    )\r\n  ) %>% \r\n  arrange(return_type) %>% \r\n  mutate_at(vars(-c(return_type, avg_liquidity, sd_liquidity, avg_volume, sd_volume)),\r\n            .funs = function(x) round(x, digits = 4)) %>% \r\n  t() %>% \r\n  as.data.frame() %>% \r\n  `colnames<-`(.[1,]) %>% \r\n  slice(-1)\r\n\r\nkable(table1) %>% \r\n  kable_paper(\"hover\", full_width = F)\r\n\r\n\r\n\r\n\r\n\r\nbelow -5%\r\n\r\n\r\nbetween -5% and -2%\r\n\r\n\r\nbetween -2% and 2%\r\n\r\n\r\nbetween 2% and 5%\r\n\r\n\r\nabove 5%\r\n\r\n\r\navg_volatility\r\n\r\n\r\n0.0829\r\n\r\n\r\n0.0391\r\n\r\n\r\n0.0218\r\n\r\n\r\n0.0350\r\n\r\n\r\n0.0765\r\n\r\n\r\nsd_volatility\r\n\r\n\r\n0.0416\r\n\r\n\r\n0.0135\r\n\r\n\r\n0.0107\r\n\r\n\r\n0.0141\r\n\r\n\r\n0.0320\r\n\r\n\r\navg_liquidity\r\n\r\n\r\n41445971\r\n\r\n\r\n30858481\r\n\r\n\r\n27199639\r\n\r\n\r\n29163226\r\n\r\n\r\n30176844\r\n\r\n\r\nsd_liquidity\r\n\r\n\r\n61709828\r\n\r\n\r\n48518623\r\n\r\n\r\n36877463\r\n\r\n\r\n34473672\r\n\r\n\r\n35416041\r\n\r\n\r\navg_hft_buy\r\n\r\n\r\n0.0336\r\n\r\n\r\n0.0454\r\n\r\n\r\n0.0551\r\n\r\n\r\n0.0547\r\n\r\n\r\n0.0518\r\n\r\n\r\nsd_hft_buy\r\n\r\n\r\n0.0354\r\n\r\n\r\n0.0548\r\n\r\n\r\n0.0625\r\n\r\n\r\n0.0583\r\n\r\n\r\n0.0525\r\n\r\n\r\navg_hft_sell\r\n\r\n\r\n0.0653\r\n\r\n\r\n0.0566\r\n\r\n\r\n0.0603\r\n\r\n\r\n0.0476\r\n\r\n\r\n0.0401\r\n\r\n\r\nsd_hft_sell\r\n\r\n\r\n0.0608\r\n\r\n\r\n0.0600\r\n\r\n\r\n0.0680\r\n\r\n\r\n0.0537\r\n\r\n\r\n0.0456\r\n\r\n\r\navg_hft\r\n\r\n\r\n0.0501\r\n\r\n\r\n0.0531\r\n\r\n\r\n0.0605\r\n\r\n\r\n0.0535\r\n\r\n\r\n0.0487\r\n\r\n\r\nsd_hft\r\n\r\n\r\n0.0415\r\n\r\n\r\n0.0510\r\n\r\n\r\n0.0592\r\n\r\n\r\n0.0506\r\n\r\n\r\n0.0443\r\n\r\n\r\navg_return\r\n\r\n\r\n-0.0700\r\n\r\n\r\n-0.0288\r\n\r\n\r\n-0.0001\r\n\r\n\r\n0.0292\r\n\r\n\r\n0.0710\r\n\r\n\r\nsd_return\r\n\r\n\r\n0.0236\r\n\r\n\r\n0.0073\r\n\r\n\r\n0.0101\r\n\r\n\r\n0.0074\r\n\r\n\r\n0.0283\r\n\r\n\r\navg_bist30_return\r\n\r\n\r\n-0.0278\r\n\r\n\r\n-0.0132\r\n\r\n\r\n0.0007\r\n\r\n\r\n0.0122\r\n\r\n\r\n0.0156\r\n\r\n\r\nsd_bist30_return\r\n\r\n\r\n0.0231\r\n\r\n\r\n0.0130\r\n\r\n\r\n0.0097\r\n\r\n\r\n0.0124\r\n\r\n\r\n0.0157\r\n\r\n\r\navg_extra_ret_market\r\n\r\n\r\n-0.0423\r\n\r\n\r\n-0.0156\r\n\r\n\r\n-0.0007\r\n\r\n\r\n0.0170\r\n\r\n\r\n0.0554\r\n\r\n\r\nsd_extra_ret_market\r\n\r\n\r\n0.0270\r\n\r\n\r\n0.0125\r\n\r\n\r\n0.0100\r\n\r\n\r\n0.0131\r\n\r\n\r\n0.0352\r\n\r\n\r\navg_volume\r\n\r\n\r\n33566193\r\n\r\n\r\n21242601\r\n\r\n\r\n14819716\r\n\r\n\r\n20296933\r\n\r\n\r\n31332308\r\n\r\n\r\nsd_volume\r\n\r\n\r\n51693115\r\n\r\n\r\n32522232\r\n\r\n\r\n23687389\r\n\r\n\r\n27891523\r\n\r\n\r\n45142746\r\n\r\n\r\nConsidering the liquidity, the average and standard deviation\r\nbelow -5% belong to non-return stocks and days. The average market\r\nvolume was experienced most intensely on non-return days.\r\nNumber\r\nof Days Above 2% and Below -2% of Returns on a Stock Basis\r\n\r\n\r\ngraph1_1 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return < -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  group_by(stock, return_type) %>% \r\n  summarise(number_of_days = n()) %>% \r\n  na.omit() %>% \r\n  pivot_wider(names_from = \"return_type\", values_from = \"number_of_days\")\r\n\r\ngraph1_2 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return < -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  group_by(stock, return_type) %>% \r\n  summarise(number_of_days = n()) %>% \r\n  na.omit()\r\n\r\nggplot(graph1_1, aes(y = stock)) + \r\n  geom_point(data = graph1_2,\r\n             aes(x = number_of_days, color = return_type), size = 3) +\r\n  scale_color_manual(values = c(\"orange\",\"#76a5af\")) +\r\n  geom_dumbbell(aes(x = `below -2%`, xend = `above 2%`),\r\n                size_x = 5, \r\n                size_xend = 5,\r\n                colour_x = \"#76a5af\",\r\n                colour_xend = \"orange\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.title = element_text(face = \"bold\", hjust = 0.5),\r\n        axis.text = element_text(size = 12, face = \"bold\")) +\r\n  guides(color = guide_legend(reverse=T)) +\r\n  labs(title = \"The Number of Days of Returns\")\r\n\r\n\r\n\r\n\r\nThe stock with the highest number of days with a return of more\r\nthan 5% is KOZAL, and the stocks with the least number of days; ENKAI,\r\nKCHOL, PETKM, SAHOL, TTKOM and TUPRS.\r\nNumber\r\nof Days Above 5% and Under -5% of Returns on a Stock Basis\r\n\r\n\r\ngraph2_1 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return < -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\"\r\n    )\r\n  ) %>% \r\n  group_by(stock, return_type) %>% \r\n  summarise(number_of_days = n()) %>% \r\n  na.omit() %>% \r\n  pivot_wider(names_from = \"return_type\", values_from = \"number_of_days\")\r\n\r\ngraph2_2 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return < -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\"\r\n    )\r\n  ) %>% \r\n  group_by(stock, return_type) %>% \r\n  summarise(number_of_days = n()) %>% \r\n  na.omit()\r\n\r\nggplot(graph2_1, aes(y = stock)) + \r\n  geom_point(data = graph2_2,\r\n             aes(x = number_of_days, color = return_type), size = 3) +\r\n  scale_color_manual(values = c(\"#80dead\",\"#f1cbff\")) +\r\n  geom_dumbbell(aes(x = `below -5%`, xend = `above 5%`),\r\n                size_x = 5, \r\n                size_xend = 5,\r\n                colour_x = \"#f1cbff\",\r\n                colour_xend = \"#80dead\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.title = element_text(face = \"bold\", hjust = 0.5),\r\n        axis.text = element_text(size = 12, face = \"bold\")) +\r\n  guides(color = guide_legend(reverse=T)) +\r\n  labs(title = \"The Number of Days of Returns\")\r\n\r\n\r\n\r\n\r\nHere, we determined the HFTs within the return limits we chose\r\nthroughout our data and averaged them on a share basis. The stock with\r\nthe highest return under -5% HFT average is TTKOM.\r\nMonthly\r\nAverage HFT Rate and Extreme Price Moving Days and Number of Stocks\r\n\r\n\r\ngraph3 <- data %>%\r\n  select(day, return, hft) %>% \r\n  mutate(day = dmy(day), \r\n         month = month(day),\r\n         year = year(day),\r\n         return_type=case_when(\r\n           return < -0.02 ~ \"below -2%\",\r\n           return > 0.02 ~ \"above 2%\"\r\n    )) %>% \r\n  na.omit() %>% \r\n  group_by(month, year) %>% \r\n  summarise(\"Extreme Price Movements\" = n(),\r\n            \"High Frequency Trading\" = mean(hft)) %>% \r\n  mutate(day = as.Date(paste0(year, \"-\", month, \"-\", 1))) %>% \r\n  arrange(day) %>% \r\n  ungroup() %>% \r\n  select(day, `Extreme Price Movements`, `High Frequency Trading`) %>% \r\n  pivot_longer(!day, names_to = \"types\", values_to = \"value\")\r\n\r\nggplot(graph3, aes(x = day, y = value, group = types, color = types)) +\r\n  geom_line() +\r\n  theme_minimal() + \r\n  theme(axis.title = element_blank(), \r\n        legend.position = \"none\") +\r\n  facet_wrap(~types, scales = \"free_y\", ncol = 1)\r\n\r\n\r\n\r\n\r\nIn the graph, we see the relationship of EPM with values on the\r\nleft and HFT with ratios on the right. Our tipping rate in EPM is minus\r\nand plus 2%. The EPM values are the sum of the days within these two\r\nextreme prices in the return. HFT rates are obtained by dividing the sum\r\nof HFTs on a monthly basis by the number of days in that month. It is\r\nseen that the number of EPM days is decreasing and the HFT ratio is\r\nincreasing. The period with the least extreme price movement; October\r\n2016, the highest is December 2015. The HFT rate reached its highest\r\nlevel in March 2017.\r\nHFT Activity in Daily\r\nReturn Ranges\r\n\r\n\r\ntable2 <- data %>% \r\n  select(hft, hft_buy, hft_sell, return) %>% \r\n  mutate(hft_buy_sell_diff = hft_buy - hft_sell,\r\n         hft_inequilibrium = (hft_buy - hft_sell)/hft, \r\n         return_type=case_when(\r\n           return <= -0.05 ~ \"below -5%\",\r\n           return > -0.05 & return <= -0.02 ~ \"between -5% and -2%\",\r\n           return > -0.02 & return <= -0.005 ~ \"between -2% and -0.5%\",\r\n           return > -0.005 & return <= 0.005 ~ \"between -0.5% and 0.5%\",\r\n           return > 0.005 & return <= 0.02 ~ \"between 0.5% and 2%\",\r\n           return > 0.02 & return <= 0.05 ~ \"between 2% and 5%\",\r\n           return > 0.05 ~ \"above 5%\"\r\n    )) %>% \r\n  group_by(return_type) %>% \r\n  summarise(\r\n    avg_hft = mean(hft),\r\n    avg_hft_buy = mean(hft_buy),\r\n    avg_hft_sell = mean(hft_sell),\r\n    avg_hft_buy_sell_diff = mean(hft_buy_sell_diff),\r\n    avg_hft_inequilibrium = mean(hft_inequilibrium, na.rm = T)\r\n  ) %>% \r\n  mutate(\r\n    return_type = factor(\r\n      return_type, levels = c(\"below -5%\",\r\n                              \"between -5% and -2%\",\r\n                              \"between -2% and -0.5%\",\r\n                              \"between -0.5% and 0.5%\",\r\n                              \"between 0.5% and 2%\",\r\n                              \"between 2% and 5%\",\r\n                              \"above 5%\")\r\n    )\r\n  ) %>% \r\n  arrange(return_type) %>% \r\n  mutate_at(vars(-c(return_type)), .funs = function(x) round(x, digits = 4)) %>% \r\n  t() %>% \r\n  as.data.frame() %>% \r\n  `colnames<-`(.[1,]) %>% \r\n  slice(-1)\r\n\r\nkable(table2) %>% \r\n  kable_paper(\"hover\", full_width = F)\r\n\r\n\r\n\r\n\r\n\r\nbelow -5%\r\n\r\n\r\nbetween -5% and -2%\r\n\r\n\r\nbetween -2% and -0.5%\r\n\r\n\r\nbetween -0.5% and 0.5%\r\n\r\n\r\nbetween 0.5% and 2%\r\n\r\n\r\nbetween 2% and 5%\r\n\r\n\r\nabove 5%\r\n\r\n\r\navg_hft\r\n\r\n\r\n0.0501\r\n\r\n\r\n0.0531\r\n\r\n\r\n0.0596\r\n\r\n\r\n0.0609\r\n\r\n\r\n0.0610\r\n\r\n\r\n0.0535\r\n\r\n\r\n0.0487\r\n\r\n\r\navg_hft_buy\r\n\r\n\r\n0.0336\r\n\r\n\r\n0.0454\r\n\r\n\r\n0.0495\r\n\r\n\r\n0.0557\r\n\r\n\r\n0.0602\r\n\r\n\r\n0.0547\r\n\r\n\r\n0.0518\r\n\r\n\r\navg_hft_sell\r\n\r\n\r\n0.0653\r\n\r\n\r\n0.0566\r\n\r\n\r\n0.0641\r\n\r\n\r\n0.0603\r\n\r\n\r\n0.0563\r\n\r\n\r\n0.0476\r\n\r\n\r\n0.0401\r\n\r\n\r\navg_hft_buy_sell_diff\r\n\r\n\r\n-0.0317\r\n\r\n\r\n-0.0112\r\n\r\n\r\n-0.0146\r\n\r\n\r\n-0.0046\r\n\r\n\r\n0.0039\r\n\r\n\r\n0.0071\r\n\r\n\r\n0.0117\r\n\r\n\r\navg_hft_inequilibrium\r\n\r\n\r\n-0.6879\r\n\r\n\r\n-0.2948\r\n\r\n\r\n-0.2616\r\n\r\n\r\n-0.0664\r\n\r\n\r\n0.0768\r\n\r\n\r\n0.1529\r\n\r\n\r\n0.2846\r\n\r\n\r\nIn the table, there are the averages of the HFT variables of the\r\ndays that fall into different return ranges. When approaching from minus\r\n5% to zero, the HFT and HFT purchase values decrease and grow after\r\nzero. In the averages of the HFT buying and selling difference, while it\r\napproaches zero, it shrinks and in the case of positive EPMs, the\r\naverages increase. In the average of the ratio of the HFT difference to\r\nthe HFT, this average value grows as the stocks and days with an EPM\r\nbelow -5% get closer to the stocks and days with a positive\r\nEPM.\r\nHFT\r\nActivity on Extreme Price Moving Days and Stocks\r\n\r\n\r\ntable3 <- data %>% \r\n   select(hft, hft_buy, hft_sell, return) %>% \r\n  mutate(hft_buy_sell_diff = hft_buy - hft_sell,\r\n         hft_inequilibrium = (hft_buy - hft_sell)/hft, \r\n         return_type=case_when(\r\n           return <= -0.05 ~ \"below -5%\",\r\n           return > -0.05 & return <= -0.02 ~ \"between -5% and -2%\",\r\n           return > -0.02 & return <= -0.005 ~ \"between -2% and -0.5%\",\r\n           return > -0.005 & return <= 0.005 ~ \"between -0.5% and 0.5%\",\r\n           return > 0.005 & return <= 0.02 ~ \"between 0.5% and 2%\",\r\n           return > 0.02 & return <= 0.05 ~ \"between 2% and 5%\",\r\n           return > 0.05 ~ \"above 5%\"\r\n    )) %>% \r\n  group_by(return_type) %>% \r\n  summarise(\r\n    avg_hft = mean(hft),\r\n    avg_hft_buy = mean(hft_buy),\r\n    avg_hft_sell = mean(hft_sell),\r\n    avg_hft_buy_sell_diff = mean(hft_buy_sell_diff),\r\n    avg_hft_inequilibrium = mean(hft_inequilibrium, na.rm = T),\r\n    p_hft = t.test(hft)$p.value,\r\n    p_hft_buy = t.test(hft_buy)$p.value,\r\n    p_hft_sell = t.test(hft_sell)$p.value,\r\n    p_hft_buy_sell_diff = t.test(hft_buy_sell_diff)$p.value,\r\n    p_hft_inequilibrium = t.test(hft_inequilibrium)$p.value\r\n  ) %>% \r\n  mutate(\r\n    return_type = factor(\r\n      return_type, levels = c(\"below -5%\",\r\n                              \"between -5% and -2%\",\r\n                              \"between -2% and -0.5%\",\r\n                              \"between -0.5% and 0.5%\",\r\n                              \"between 0.5% and 2%\",\r\n                              \"between 2% and 5%\",\r\n                              \"above 5%\")\r\n    )\r\n  ) %>% \r\n  arrange(return_type) %>% \r\n  select(return_type, avg_hft, p_hft, avg_hft_buy, p_hft_buy, avg_hft_sell,\r\n         p_hft_sell, avg_hft_buy_sell_diff, p_hft_buy_sell_diff, avg_hft_inequilibrium, p_hft_inequilibrium) %>% \r\n  mutate_at(vars(-c(return_type)), .funs = function(x) round(x, digits = 4)) %>% \r\n  mutate_if(is.character, as.numeric) %>% \r\n  t() %>% \r\n  as.data.frame() %>% \r\n  `colnames<-`(.[1,]) %>% \r\n  slice(-1) %>% \r\n  mutate_if(is.character, as.numeric) %>% \r\n  mutate_all(.funs = function(x) x - .[,4])\r\n  \r\nkable(table3) %>% \r\n  kable_paper(\"hover\", full_width = F)\r\n\r\n\r\n\r\n\r\n\r\nbelow -5%\r\n\r\n\r\nbetween -5% and -2%\r\n\r\n\r\nbetween -2% and -0.5%\r\n\r\n\r\nbetween -0.5% and 0.5%\r\n\r\n\r\nbetween 0.5% and 2%\r\n\r\n\r\nbetween 2% and 5%\r\n\r\n\r\nabove 5%\r\n\r\n\r\navg_hft\r\n\r\n\r\n-0.0108\r\n\r\n\r\n-0.0078\r\n\r\n\r\n-0.0013\r\n\r\n\r\n0\r\n\r\n\r\n0.0001\r\n\r\n\r\n-0.0074\r\n\r\n\r\n-0.0122\r\n\r\n\r\np_hft\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\navg_hft_buy\r\n\r\n\r\n-0.0221\r\n\r\n\r\n-0.0103\r\n\r\n\r\n-0.0062\r\n\r\n\r\n0\r\n\r\n\r\n0.0045\r\n\r\n\r\n-0.0010\r\n\r\n\r\n-0.0039\r\n\r\n\r\np_hft_buy\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\navg_hft_sell\r\n\r\n\r\n0.0050\r\n\r\n\r\n-0.0037\r\n\r\n\r\n0.0038\r\n\r\n\r\n0\r\n\r\n\r\n-0.0040\r\n\r\n\r\n-0.0127\r\n\r\n\r\n-0.0202\r\n\r\n\r\np_hft_sell\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\navg_hft_buy_sell_diff\r\n\r\n\r\n-0.0271\r\n\r\n\r\n-0.0066\r\n\r\n\r\n-0.0100\r\n\r\n\r\n0\r\n\r\n\r\n0.0085\r\n\r\n\r\n0.0117\r\n\r\n\r\n0.0163\r\n\r\n\r\np_hft_buy_sell_diff\r\n\r\n\r\n-0.0020\r\n\r\n\r\n-0.0020\r\n\r\n\r\n-0.0020\r\n\r\n\r\n0\r\n\r\n\r\n0.0034\r\n\r\n\r\n-0.0019\r\n\r\n\r\n0.0097\r\n\r\n\r\navg_hft_inequilibrium\r\n\r\n\r\n-0.6215\r\n\r\n\r\n-0.2284\r\n\r\n\r\n-0.1952\r\n\r\n\r\n0\r\n\r\n\r\n0.1432\r\n\r\n\r\n0.2193\r\n\r\n\r\n0.3510\r\n\r\n\r\np_hft_inequilibrium\r\n\r\n\r\n-0.0005\r\n\r\n\r\n-0.0005\r\n\r\n\r\n-0.0005\r\n\r\n\r\n0\r\n\r\n\r\n-0.0005\r\n\r\n\r\n-0.0005\r\n\r\n\r\n0.0004\r\n\r\n\r\nThe table shows that HFT activity reduces taking a buy position\r\nduring negative-end price movements, while it reduces\r\nselling-positioning during positive-end price movements.\r\nIt was 0 (zero) because the p values were too small.\r\nExtreme\r\nprice movements and HFT relationship – Regression models\r\n\\(HFT_{i,t}= EPM_{i,t}^{+0.05} +\r\nEPM_{i,t}^{-0.05} + \\epsilon_{i,t}\\)\r\n\\(HFT_{i,t}= EPM_{i,t}^{+0.02} +\r\nEPM_{i,t}^{-0.02} + \\epsilon_{i,t}\\)\r\n\\(HFT_{i,t}= EPM_{i,t}^{+0.05} +\r\nEPM_{i,t}^{-0.05} + Volume_{i,t} + Liquidity_{i,t} + Volatility_{i,t} +\r\n\\epsilon_{i,t}\\)\r\n\\(HFT_{i,t}= EPM_{i,t}^{+0.02} +\r\nEPM_{i,t}^{-0.02} + Volume_{i,t} + Liquidity_{i,t} + Volatility_{i,t} +\r\n\\epsilon_{i,t}\\)\r\nTotal HFT Ratio Determinants\r\n\r\n\r\ndata_all_1 <- data %>% \r\n  select(hft, return) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft = (hft - mean(hft)) / sd(hft)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_all_1 <- lm(hft ~ `return_type_above 5%` + `return_type_below -5%`, data = data_all_1)\r\nstargazer(model_all_1, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                    hft            \r\n---------------------------------------------------\r\n`return_type_above 5%`           -0.179**          \r\n                                  (0.084)          \r\n                                                   \r\n`return_type_below -5%`           -0.154*          \r\n                                  (0.093)          \r\n                                                   \r\nConstant                           0.004           \r\n                                  (0.010)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.001           \r\nAdjusted R2                        0.001           \r\nResidual Std. Error         1.000 (df = 10167)     \r\nF Statistic               3.589** (df = 2; 10167)  \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_all_2 <- lm(hft ~ `return_type_above 2%` + `return_type_below -2%`, data = data_all_1)\r\nstargazer(model_all_2, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                    hft            \r\n---------------------------------------------------\r\n`return_type_above 2%`           -0.115***         \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`          -0.123***         \r\n                                  (0.034)          \r\n                                                   \r\nConstant                          0.025**          \r\n                                  (0.011)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.002           \r\nAdjusted R2                        0.002           \r\nResidual Std. Error         0.999 (df = 10167)     \r\nF Statistic              12.039*** (df = 2; 10167) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\ndata_all_2 <- data %>% \r\n  select(hft, return, volume, liquidity, volatility) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft = (hft - mean(hft)) / sd(hft),\r\n         volume = (volume - mean(volume)) / sd(volume),\r\n         liquidity =(liquidity - mean(liquidity)) / sd(liquidity)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_all_3 <- lm(hft ~ `return_type_above 5%` + `return_type_below -5%` +\r\n                    volume + liquidity + volatility, data = data_all_2)\r\nstargazer(model_all_3, type = \"text\") \r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                    hft            \r\n---------------------------------------------------\r\n`return_type_above 5%`            0.159*           \r\n                                  (0.088)          \r\n                                                   \r\n`return_type_below -5%`           0.230**          \r\n                                  (0.098)          \r\n                                                   \r\nvolume                           -0.246***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                         -0.001           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -3.811***         \r\n                                  (0.687)          \r\n                                                   \r\nConstant                         0.096***          \r\n                                  (0.020)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.067           \r\nAdjusted R2                        0.067           \r\nResidual Std. Error         0.966 (df = 10164)     \r\nF Statistic             146.079*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_all_4 <- lm(hft ~ `return_type_above 2%` + `return_type_below -2%` + \r\n                    volume + liquidity + volatility, data = data_all_2)\r\nstargazer(model_all_4, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                    hft            \r\n---------------------------------------------------\r\n`return_type_above 2%`            -0.040           \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`           -0.029           \r\n                                  (0.034)          \r\n                                                   \r\nvolume                           -0.245***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                         -0.001           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -2.594***         \r\n                                  (0.624)          \r\n                                                   \r\nConstant                         0.076***          \r\n                                  (0.018)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.067           \r\nAdjusted R2                        0.066           \r\nResidual Std. Error         0.966 (df = 10164)     \r\nF Statistic             144.902*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nBuy-side HFT Ratio\r\nDeterminants\r\n\r\n\r\ndata_buy_1 <- data %>% \r\n  select(hft_buy, return) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft_buy = (hft_buy - mean(hft_buy)) / sd(hft_buy)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_buy_1 <- lm(hft_buy ~ `return_type_above 5%` + `return_type_below -5%`, data = data_buy_1)\r\nstargazer(model_buy_1, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                  hft_buy          \r\n---------------------------------------------------\r\n`return_type_above 5%`            -0.037           \r\n                                  (0.084)          \r\n                                                   \r\n`return_type_below -5%`          -0.336***         \r\n                                  (0.093)          \r\n                                                   \r\nConstant                           0.004           \r\n                                  (0.010)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.001           \r\nAdjusted R2                        0.001           \r\nResidual Std. Error         0.999 (df = 10167)     \r\nF Statistic              6.599*** (df = 2; 10167)  \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_buy_2 <- lm(hft_buy ~ `return_type_above 2%` + `return_type_below -2%`, data = data_buy_1)\r\nstargazer(model_buy_2, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                  hft_buy          \r\n---------------------------------------------------\r\n`return_type_above 2%`            -0.001           \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`          -0.153***         \r\n                                  (0.034)          \r\n                                                   \r\nConstant                           0.015           \r\n                                  (0.011)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.002           \r\nAdjusted R2                        0.002           \r\nResidual Std. Error         0.999 (df = 10167)     \r\nF Statistic              10.261*** (df = 2; 10167) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\ndata_buy_2 <- data %>% \r\n  select(hft_buy, return, volume, liquidity, volatility) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft_buy = (hft_buy - mean(hft_buy)) / sd(hft_buy),\r\n         volume = (volume - mean(volume)) / sd(volume),\r\n         liquidity =(liquidity - mean(liquidity)) / sd(liquidity)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_buy_3 <- lm(hft_buy ~ `return_type_above 5%` + `return_type_below -5%` \r\n                  + volume + liquidity + volatility, data = data_buy_2)\r\nstargazer(model_buy_3, type = \"text\") \r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                  hft_buy          \r\n---------------------------------------------------\r\n`return_type_above 5%`           0.256***          \r\n                                  (0.089)          \r\n                                                   \r\n`return_type_below -5%`           -0.004           \r\n                                  (0.099)          \r\n                                                   \r\nvolume                           -0.209***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                         0.0004           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -3.339***         \r\n                                  (0.693)          \r\n                                                   \r\nConstant                         0.085***          \r\n                                  (0.020)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.049           \r\nAdjusted R2                        0.049           \r\nResidual Std. Error         0.975 (df = 10164)     \r\nF Statistic             105.283*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_buy_4 <- lm(hft_buy ~ `return_type_above 2%` + `return_type_below -2%` \r\n                  + volume + liquidity + volatility, data = data_buy_2)\r\nstargazer(model_buy_4, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                  hft_buy          \r\n---------------------------------------------------\r\n`return_type_above 2%`            0.069**          \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`           -0.066*          \r\n                                  (0.035)          \r\n                                                   \r\nvolume                           -0.209***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                          0.001           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -2.658***         \r\n                                  (0.630)          \r\n                                                   \r\nConstant                         0.068***          \r\n                                  (0.019)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.049           \r\nAdjusted R2                        0.049           \r\nResidual Std. Error         0.975 (df = 10164)     \r\nF Statistic             105.651*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nSell Side HFT Ratio\r\nDeterminants\r\n\r\n\r\ndata_sell_1 <- data %>% \r\n  select(hft_sell, return) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft_sell = (hft_sell - mean(hft_sell)) / sd(hft_sell)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_sell_1 <- lm(hft_sell ~ `return_type_above 5%` + `return_type_below -5%`, data = data_sell_1)\r\nstargazer(model_sell_1, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                 hft_sell          \r\n---------------------------------------------------\r\n`return_type_above 5%`           -0.278***         \r\n                                  (0.084)          \r\n                                                   \r\n`return_type_below -5%`            0.106           \r\n                                  (0.093)          \r\n                                                   \r\nConstant                           0.003           \r\n                                  (0.010)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.001           \r\nAdjusted R2                        0.001           \r\nResidual Std. Error         0.999 (df = 10167)     \r\nF Statistic              6.165*** (df = 2; 10167)  \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_sell_2 <- lm(hft_sell ~ `return_type_above 2%` + `return_type_below -2%`, data = data_sell_1)\r\nstargazer(model_sell_2, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                 hft_sell          \r\n---------------------------------------------------\r\n`return_type_above 2%`           -0.189***         \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`           -0.052           \r\n                                  (0.034)          \r\n                                                   \r\nConstant                          0.027**          \r\n                                  (0.011)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.004           \r\nAdjusted R2                        0.004           \r\nResidual Std. Error         0.998 (df = 10167)     \r\nF Statistic              19.030*** (df = 2; 10167) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\ndata_sell_2 <- data %>% \r\n  select(hft_sell, return, volume, liquidity, volatility) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft_sell = (hft_sell - mean(hft_sell)) / sd(hft_sell),\r\n         volume = (volume - mean(volume)) / sd(volume),\r\n         liquidity =(liquidity - mean(liquidity)) / sd(liquidity)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_sell_3 <- lm(hft_sell ~ `return_type_above 5%` + `return_type_below -5%` + \r\n                     volume + liquidity + volatility, data = data_sell_2)\r\nstargazer(model_sell_3, type = \"text\") \r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                 hft_sell          \r\n---------------------------------------------------\r\n`return_type_above 5%`            -0.020           \r\n                                  (0.089)          \r\n                                                   \r\n`return_type_below -5%`          0.397***          \r\n                                  (0.099)          \r\n                                                   \r\nvolume                           -0.222***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                          0.007           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -2.537***         \r\n                                  (0.693)          \r\n                                                   \r\nConstant                         0.063***          \r\n                                  (0.020)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.051           \r\nAdjusted R2                        0.051           \r\nResidual Std. Error         0.974 (df = 10164)     \r\nF Statistic             109.717*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_sell_4 <- lm(hft_sell ~ `return_type_above 2%` + `return_type_below -2%` + \r\n                     volume + liquidity + volatility, data = data_sell_2)\r\nstargazer(model_sell_4, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                 hft_sell          \r\n---------------------------------------------------\r\n`return_type_above 2%`           -0.134***         \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`            0.016           \r\n                                  (0.035)          \r\n                                                   \r\nvolume                           -0.222***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                          0.008           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                        -1.232*          \r\n                                  (0.629)          \r\n                                                   \r\nConstant                          0.047**          \r\n                                  (0.019)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.052           \r\nAdjusted R2                        0.051           \r\nResidual Std. Error         0.974 (df = 10164)     \r\nF Statistic             110.402*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nAs a result;\r\nLower HFT activity was observed on stocks and days with extreme price\r\nmovements.\r\nHFT decreased on the sell side during positive extreme price\r\nmovements.\r\nHFT decreased on the buy side during negative extreme price\r\nmovements\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-08-hft-en/hft-en_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2022-05-08T22:38:46+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-08-hft-tr/",
    "title": "Yüksek Frekanslı İşlemlerin Borsa İstanbul’da Uç Fiyat Hareketleri Çerçevesinde İncelenmesi",
    "description": "Bu çalışmada Borsa İstanbul’da yüksek frekanslı işlemin işlemler ((High Frequency Trading), (HFT))’in varoluşuna ilişkin analizler yaptım. Baz aldığım nokta; uç fiyat hareketleri (((EPM’ler), (Extreme Price Movements)) anındaki yüksek frekanslı işlemlerin davranışlarını ve piyasa payını inceleyeceğim.",
    "author": [
      {
        "name": "Irem Dastan",
        "url": {}
      }
    ],
    "date": "2022-05-08",
    "categories": [
      "Finance",
      "Market Microstructure"
    ],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(knitr)\r\nlibrary(kableExtra)\r\nlibrary(ggalt)\r\nlibrary(lubridate)\r\nlibrary(stargazer)\r\nlibrary(fastDummies)\r\n\r\ndata <- read.csv(\"data.csv\") #Veriye Github üzerinden erisebilirsiniz.\r\nnames(data)[1] <- \"stock\" \r\n\r\n\r\n\r\nBu çalışmada Borsa İstanbul’da yüksek frekanslı işlemin ((High\r\nFrequency Trading), (HFT))’in varoluşuna ilişkin analizler yaptım. Baz\r\naldığım nokta; uç fiyat hareketleri (((EPM’ler), (Extreme Price\r\nMovements)) anındaki yüksek frekanslı işlemlerin davranışlarını ve\r\npiyasa payını inceleyeceğim.\r\nBorsaların tamamen otomatik hale gelmesi piyasada gerçekleşen işlem\r\nsayısını artırmış ve aracıların teknoloji kullanımını genişletmelerini\r\nsağlamıştır. Verilerin işlem akışı, piyasa bilgileri akışına hızlı bir\r\nşekilde işlenmesi ve tepki verme yeteneğine dayanan yazılımların\r\narkasında alım satım yapılması, kısa sürede çok sayıda işlem yapılmasını\r\nmümkün kılmıştır. Ancak yine de finansal piyasalarda, yatırım yapmak\r\niçin verilerin kullanılması veya işlemlere hızlı bir şekilde girebilmek\r\niçin süratle ilgili sorunlar vardır. Bu sebeple finansal piyasalarda en\r\nhızlı aktörlerin birbirleriyle rekabet ettikleri bir hız yarışı\r\nmevcuttur. Böylece artık piyasalar insanlar tarafından yapılan\r\nalım-satım işlemleri ile değil, bilgisayar algoritmaları ile domine\r\nedilmektedir.\r\nHFT; bir saniyenin kesirlerinde, binlerce emir gönderimi, yüksek\r\noranda emir iptalleri ve gün içi marjinal kâr hedefi ile\r\nözdeşleştirilebilen saniye veya milisaniye cinsinden pozisyon tutan bir\r\nişlem tipidir. Kısaca; “HFT, düşük milisaniye gecikmelerinde çok sayıda\r\nsipariş gönderme teknolojik yeteneğinden yararlanır” (Ersan ve Ekinci,\r\n2016).\r\nHFT algoritmaları birbirleri ile rekabet ettikçe, iki zorlukla\r\nkarşılaşırlar:\r\nHer mikro saniyede büyük miktarda veri alırlar.\r\nGözlemlenen veriler üzerinde oldukça hızlı hareket edebilmeliler,\r\nçünkü gözlemledikleri sinyallerin kârlılığı çok çabuk azalır.\r\nHFT firmalarının likidite sağlama ve piyasadaki fiyat arbitrajında\r\noynadıkları baskın rol, ticaret alanlarının piyasa payını doğrudan\r\netkiler. Arbitrajlara katılımı kısa süreli alım-satım işlemleri ve\r\nyüksek hacimleriyle küçük fiyat farklarından kâr elde edip böylece\r\nbirden fazla piyasada işlem gören hisselerin fiyat farklarından temin\r\nedilmektedir.\r\n30 Kasım 2015 tarihinde Pay Piyasasında devreye alınan BISTECH\r\nplatformu HFT dahiliyetine imkan vermiştir. Borsa İstanbul’da HFT payı,\r\nABD ve Avrupa ülkeleri kadar gelişmiş değildir.\r\nHFT ile AT (Algorithmic Trading)’nin arasındaki fark; AT daha\r\nkapsamlıdır ve HFT, AT’nin alt kümesidir. AT bilgisayar ortamında\r\ntanımlanan koşullar ile alım satım sağlayan bir yapıdır, HFT ise çok\r\nküçük saniyelerde oluşan fırsatları değerlendirmektedir. Kısacası HFT,\r\nAT’nin bir türüdür.\r\n\r\n\r\n\r\nBIST30 endeksinde listelenen hisse senetleri.\r\n\r\n\r\n\r\nAralık 2015 – Mart 2017 arası 16 aylık dönem, 339 işlem\r\ngünü.\r\n\r\n\r\n\r\nGün-içi emir-işlem defterlerinden elde edilmiş değişkenlerin\r\ngünlük düzeyde tutulan hallerini Ekinci ve Ersan (2020) çalışmasından\r\ntemini.\r\nÇalışmadaki değişkenler; HFT toplam, HFT alım-satım tarafları, HFT\r\nalım-satım farkı (HFT dengesizliği)’dır. Kontrol değişkenleri; işlem\r\nhacmi, likidite ve volatilitedir. Temel bağımsız değişkenler olan kukla\r\ndeğişkenleri ise; uç pozitif fiyat hareketleri (%2 ve %5 üzeri getirili\r\nolan hisse ve günler), ve uç negatif fiyat hareketleri (eksi %2 ve eksi\r\n%5 altı getirili olan hisse ve günler)’dir.\r\nÜç aşamada analizleri yapıyorum.\r\nHisse ve getiri aralığı bazlı\r\nT-test\r\nRegresyon analizi\r\nHFT’nin Hesaplanması\r\nÖncelikle veride bazı emirler HFT emri olarak işaretleniyor. Bunu iki\r\naşamada yapıyoruz.\r\nBirincisi,\r\n1 saniye veya daha kısa sürede gelen en az iki mesaj (emir gönderim,\r\ndeğişiklik, iptal) içeren emirler\r\nİkincisi,\r\naşamada belirlenen HFT emirlerinin herhangi bir mesajı ile aynı\r\nsaniyede ve aynı büyüklükte gelen aynı hissedeki diğer emirler olarak\r\nbelirliyoruz.\r\n\\(HFT\\ ratio_{i,t}=\\frac{Electronic\\\r\nmessage_{i,t}^{HFT}}{Electronic\\ message_{all^{HFT}}}\\)\r\n\\(Liquidity_{i,t}= \\sum_{j=1}^{N}\r\nVolume_{i,j,t}*(\\frac{Duration_{i,j,t}}{Duration_{total}})\\)\r\nAnalizler\r\nGünlük\r\nGetiri Aralıklarında Değişkenlerin İstatistikleri\r\n\r\n\r\ntable1 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > -0.05 & return <= -0.02 ~ \"between -5% and -2%\",\r\n      return > -0.02 & return <= 0.02 ~ \"between -2% and 2%\",\r\n      return > 0.02 & return <= 0.05 ~ \"between 2% and 5%\",\r\n      return > 0.05 ~ \"above 5%\"\r\n    )\r\n  ) %>% \r\n  group_by(return_type) %>% \r\n  summarise(\r\n    avg_volatility = mean(volatility),\r\n    sd_volatility = sd(volatility),\r\n    avg_liquidity = mean(liquidity),\r\n    sd_liquidity = sd(liquidity),\r\n    avg_hft_buy = mean(hft_buy),\r\n    sd_hft_buy = sd(hft_buy),\r\n    avg_hft_sell = mean(hft_sell),\r\n    sd_hft_sell = sd(hft_sell),\r\n    avg_hft = mean(hft),\r\n    sd_hft = sd(hft),\r\n    avg_return = mean(return),\r\n    sd_return = sd(return),\r\n    avg_bist30_return = mean(bist30_return),\r\n    sd_bist30_return = sd(bist30_return),\r\n    avg_extra_ret_market = mean(extra_ret_market),\r\n    sd_extra_ret_market = sd(extra_ret_market),\r\n    avg_volume = mean(volume),\r\n    sd_volume = sd(volume)\r\n  ) %>% \r\n  mutate(\r\n    return_type = factor(\r\n      return_type, levels = c(\"below -5%\",\r\n                              \"between -5% and -2%\",\r\n                              \"between -2% and 2%\",\r\n                              \"between 2% and 5%\",\r\n                              \"above 5%\")\r\n    )\r\n  ) %>% \r\n  arrange(return_type) %>% \r\n  mutate_at(vars(-c(return_type, avg_liquidity, sd_liquidity, avg_volume, sd_volume)),\r\n            .funs = function(x) round(x, digits = 4)) %>% \r\n  t() %>% \r\n  as.data.frame() %>% \r\n  `colnames<-`(.[1,]) %>% \r\n  slice(-1)\r\n\r\nkable(table1) %>% \r\n  kable_paper(\"hover\", full_width = F)\r\n\r\n\r\n\r\n\r\n\r\nbelow -5%\r\n\r\n\r\nbetween -5% and -2%\r\n\r\n\r\nbetween -2% and 2%\r\n\r\n\r\nbetween 2% and 5%\r\n\r\n\r\nabove 5%\r\n\r\n\r\navg_volatility\r\n\r\n\r\n0.0829\r\n\r\n\r\n0.0391\r\n\r\n\r\n0.0218\r\n\r\n\r\n0.0350\r\n\r\n\r\n0.0765\r\n\r\n\r\nsd_volatility\r\n\r\n\r\n0.0416\r\n\r\n\r\n0.0135\r\n\r\n\r\n0.0107\r\n\r\n\r\n0.0141\r\n\r\n\r\n0.0320\r\n\r\n\r\navg_liquidity\r\n\r\n\r\n41445971\r\n\r\n\r\n30858481\r\n\r\n\r\n27199639\r\n\r\n\r\n29163226\r\n\r\n\r\n30176844\r\n\r\n\r\nsd_liquidity\r\n\r\n\r\n61709828\r\n\r\n\r\n48518623\r\n\r\n\r\n36877463\r\n\r\n\r\n34473672\r\n\r\n\r\n35416041\r\n\r\n\r\navg_hft_buy\r\n\r\n\r\n0.0336\r\n\r\n\r\n0.0454\r\n\r\n\r\n0.0551\r\n\r\n\r\n0.0547\r\n\r\n\r\n0.0518\r\n\r\n\r\nsd_hft_buy\r\n\r\n\r\n0.0354\r\n\r\n\r\n0.0548\r\n\r\n\r\n0.0625\r\n\r\n\r\n0.0583\r\n\r\n\r\n0.0525\r\n\r\n\r\navg_hft_sell\r\n\r\n\r\n0.0653\r\n\r\n\r\n0.0566\r\n\r\n\r\n0.0603\r\n\r\n\r\n0.0476\r\n\r\n\r\n0.0401\r\n\r\n\r\nsd_hft_sell\r\n\r\n\r\n0.0608\r\n\r\n\r\n0.0600\r\n\r\n\r\n0.0680\r\n\r\n\r\n0.0537\r\n\r\n\r\n0.0456\r\n\r\n\r\navg_hft\r\n\r\n\r\n0.0501\r\n\r\n\r\n0.0531\r\n\r\n\r\n0.0605\r\n\r\n\r\n0.0535\r\n\r\n\r\n0.0487\r\n\r\n\r\nsd_hft\r\n\r\n\r\n0.0415\r\n\r\n\r\n0.0510\r\n\r\n\r\n0.0592\r\n\r\n\r\n0.0506\r\n\r\n\r\n0.0443\r\n\r\n\r\navg_return\r\n\r\n\r\n-0.0700\r\n\r\n\r\n-0.0288\r\n\r\n\r\n-0.0001\r\n\r\n\r\n0.0292\r\n\r\n\r\n0.0710\r\n\r\n\r\nsd_return\r\n\r\n\r\n0.0236\r\n\r\n\r\n0.0073\r\n\r\n\r\n0.0101\r\n\r\n\r\n0.0074\r\n\r\n\r\n0.0283\r\n\r\n\r\navg_bist30_return\r\n\r\n\r\n-0.0278\r\n\r\n\r\n-0.0132\r\n\r\n\r\n0.0007\r\n\r\n\r\n0.0122\r\n\r\n\r\n0.0156\r\n\r\n\r\nsd_bist30_return\r\n\r\n\r\n0.0231\r\n\r\n\r\n0.0130\r\n\r\n\r\n0.0097\r\n\r\n\r\n0.0124\r\n\r\n\r\n0.0157\r\n\r\n\r\navg_extra_ret_market\r\n\r\n\r\n-0.0423\r\n\r\n\r\n-0.0156\r\n\r\n\r\n-0.0007\r\n\r\n\r\n0.0170\r\n\r\n\r\n0.0554\r\n\r\n\r\nsd_extra_ret_market\r\n\r\n\r\n0.0270\r\n\r\n\r\n0.0125\r\n\r\n\r\n0.0100\r\n\r\n\r\n0.0131\r\n\r\n\r\n0.0352\r\n\r\n\r\navg_volume\r\n\r\n\r\n33566193\r\n\r\n\r\n21242601\r\n\r\n\r\n14819716\r\n\r\n\r\n20296933\r\n\r\n\r\n31332308\r\n\r\n\r\nsd_volume\r\n\r\n\r\n51693115\r\n\r\n\r\n32522232\r\n\r\n\r\n23687389\r\n\r\n\r\n27891523\r\n\r\n\r\n45142746\r\n\r\n\r\nLikiditeye bakıldığında ortalama ve standart sapması en büyük\r\nolan %-5 altı getirisiz hisse ve günlere aittir. Piyasa hacmi ortalaması\r\ngetirisiz günlerde en yoğun şekilde yaşanmıştır.\r\nHisse\r\nBazında Getirilerin %2 üzeri ve %-2 altı Günlerinin Sayısı\r\n\r\n\r\ngraph1_1 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return < -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  group_by(stock, return_type) %>% \r\n  summarise(number_of_days = n()) %>% \r\n  na.omit() %>% \r\n  pivot_wider(names_from = \"return_type\", values_from = \"number_of_days\")\r\n\r\ngraph1_2 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return < -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  group_by(stock, return_type) %>% \r\n  summarise(number_of_days = n()) %>% \r\n  na.omit()\r\n\r\nggplot(graph1_1, aes(y = stock)) + \r\n  geom_point(data = graph1_2,\r\n             aes(x = number_of_days, color = return_type), size = 3) +\r\n  scale_color_manual(values = c(\"orange\",\"#76a5af\")) +\r\n  geom_dumbbell(aes(x = `below -2%`, xend = `above 2%`),\r\n                size_x = 5, \r\n                size_xend = 5,\r\n                colour_x = \"#76a5af\",\r\n                colour_xend = \"orange\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.title = element_text(face = \"bold\", hjust = 0.5),\r\n        axis.text = element_text(size = 12, face = \"bold\")) +\r\n  guides(color = guide_legend(reverse=T)) +\r\n  labs(title = \"The Number of Days of Returns\")\r\n\r\n\r\n\r\n\r\n%5 üzeri getirili gün sayısının en fazla olduğu hisse senedi\r\nKOZAL’dır, en az günlü olan hisse senetleri ise; ENKAI, KCHOL, PETKM,\r\nSAHOL, TTKOM ve TUPRS’tır.\r\nHisse\r\nBazında Getirilerin %5 üzeri ve %-5 altı Günlerinin Sayısı\r\n\r\n\r\ngraph2_1 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return < -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\"\r\n    )\r\n  ) %>% \r\n  group_by(stock, return_type) %>% \r\n  summarise(number_of_days = n()) %>% \r\n  na.omit() %>% \r\n  pivot_wider(names_from = \"return_type\", values_from = \"number_of_days\")\r\n\r\ngraph2_2 <- data %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return < -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\"\r\n    )\r\n  ) %>% \r\n  group_by(stock, return_type) %>% \r\n  summarise(number_of_days = n()) %>% \r\n  na.omit()\r\n\r\nggplot(graph2_1, aes(y = stock)) + \r\n  geom_point(data = graph2_2,\r\n             aes(x = number_of_days, color = return_type), size = 3) +\r\n  scale_color_manual(values = c(\"#80dead\",\"#f1cbff\")) +\r\n  geom_dumbbell(aes(x = `below -5%`, xend = `above 5%`),\r\n                size_x = 5, \r\n                size_xend = 5,\r\n                colour_x = \"#f1cbff\",\r\n                colour_xend = \"#80dead\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.title = element_text(face = \"bold\", hjust = 0.5),\r\n        axis.text = element_text(size = 12, face = \"bold\")) +\r\n  guides(color = guide_legend(reverse=T)) +\r\n  labs(title = \"The Number of Days of Returns\")\r\n\r\n\r\n\r\n\r\nBurada verimiz boyunca seçtiğimiz getiri sınırları dahilinde\r\nHFT’leri belirleyip hisse bazında ortalamasını aldık. Getirisi %-5 altı\r\nHFT ortalaması en fazla olan hisse senedi TTKOM’dur.\r\nAylık\r\nOrtalama HFT Oranı ve Uç Fiyat Hareketli Gün-Hisse Sayısı\r\n\r\n\r\ngraph3 <- data %>%\r\n  select(day, return, hft) %>% \r\n  mutate(day = dmy(day), \r\n         month = month(day),\r\n         year = year(day),\r\n         return_type=case_when(\r\n           return < -0.02 ~ \"below -2%\",\r\n           return > 0.02 ~ \"above 2%\"\r\n    )) %>% \r\n  na.omit() %>% \r\n  group_by(month, year) %>% \r\n  summarise(\"Extreme Price Movements\" = n(),\r\n            \"High Frequency Trading\" = mean(hft)) %>% \r\n  mutate(day = as.Date(paste0(year, \"-\", month, \"-\", 1))) %>% \r\n  arrange(day) %>% \r\n  ungroup() %>% \r\n  select(day, `Extreme Price Movements`, `High Frequency Trading`) %>% \r\n  pivot_longer(!day, names_to = \"types\", values_to = \"value\")\r\n\r\nggplot(graph3, aes(x = day, y = value, group = types, color = types)) +\r\n  geom_line() +\r\n  theme_minimal() + \r\n  theme(axis.title = element_blank(), \r\n        legend.position = \"none\") +\r\n  facet_wrap(~types, scales = \"free_y\", ncol = 1)\r\n\r\n\r\n\r\n\r\nGrafikte sol tarafta değerleri olan EPM’yi ve sağ tarafta\r\noranları bulunan HFT’nin ilişkisini görmekteyiz. EPM’deki uç fiyat\r\noranımız eksi ve artı %2’dir. EPM değerleri, getirideki bu iki uç fiyat\r\ndahilinde gün sayılarının toplamıdır. HFT oranları ise, ay bazında\r\nHFT’lerin toplamının o ayki gün sayısına bölümü ile elde edilmiştir. EPM\r\ngünlerinin sayısı azalmakta ve HFT oranının arttığı görülmektedir. Uç\r\nfiyat hareketinin en az olduğu periyot; Ekim 2016, en fazla olduğu ise\r\nAralık 2015’tir. HFT oranı Mart 2017’de en yüksek seviyeye\r\nulaşmıştır.\r\nGünlük Getiri\r\nAralıklarında HFT Aktivitesi\r\n\r\n\r\ntable2 <- data %>% \r\n  select(hft, hft_buy, hft_sell, return) %>% \r\n  mutate(hft_buy_sell_diff = hft_buy - hft_sell,\r\n         hft_inequilibrium = (hft_buy - hft_sell)/hft, \r\n         return_type=case_when(\r\n           return <= -0.05 ~ \"below -5%\",\r\n           return > -0.05 & return <= -0.02 ~ \"between -5% and -2%\",\r\n           return > -0.02 & return <= -0.005 ~ \"between -2% and -0.5%\",\r\n           return > -0.005 & return <= 0.005 ~ \"between -0.5% and 0.5%\",\r\n           return > 0.005 & return <= 0.02 ~ \"between 0.5% and 2%\",\r\n           return > 0.02 & return <= 0.05 ~ \"between 2% and 5%\",\r\n           return > 0.05 ~ \"above 5%\"\r\n    )) %>% \r\n  group_by(return_type) %>% \r\n  summarise(\r\n    avg_hft = mean(hft),\r\n    avg_hft_buy = mean(hft_buy),\r\n    avg_hft_sell = mean(hft_sell),\r\n    avg_hft_buy_sell_diff = mean(hft_buy_sell_diff),\r\n    avg_hft_inequilibrium = mean(hft_inequilibrium, na.rm = T)\r\n  ) %>% \r\n  mutate(\r\n    return_type = factor(\r\n      return_type, levels = c(\"below -5%\",\r\n                              \"between -5% and -2%\",\r\n                              \"between -2% and -0.5%\",\r\n                              \"between -0.5% and 0.5%\",\r\n                              \"between 0.5% and 2%\",\r\n                              \"between 2% and 5%\",\r\n                              \"above 5%\")\r\n    )\r\n  ) %>% \r\n  arrange(return_type) %>% \r\n  mutate_at(vars(-c(return_type)), .funs = function(x) round(x, digits = 4)) %>% \r\n  t() %>% \r\n  as.data.frame() %>% \r\n  `colnames<-`(.[1,]) %>% \r\n  slice(-1)\r\n\r\nkable(table2) %>% \r\n  kable_paper(\"hover\", full_width = F)\r\n\r\n\r\n\r\n\r\n\r\nbelow -5%\r\n\r\n\r\nbetween -5% and -2%\r\n\r\n\r\nbetween -2% and -0.5%\r\n\r\n\r\nbetween -0.5% and 0.5%\r\n\r\n\r\nbetween 0.5% and 2%\r\n\r\n\r\nbetween 2% and 5%\r\n\r\n\r\nabove 5%\r\n\r\n\r\navg_hft\r\n\r\n\r\n0.0501\r\n\r\n\r\n0.0531\r\n\r\n\r\n0.0596\r\n\r\n\r\n0.0609\r\n\r\n\r\n0.0610\r\n\r\n\r\n0.0535\r\n\r\n\r\n0.0487\r\n\r\n\r\navg_hft_buy\r\n\r\n\r\n0.0336\r\n\r\n\r\n0.0454\r\n\r\n\r\n0.0495\r\n\r\n\r\n0.0557\r\n\r\n\r\n0.0602\r\n\r\n\r\n0.0547\r\n\r\n\r\n0.0518\r\n\r\n\r\navg_hft_sell\r\n\r\n\r\n0.0653\r\n\r\n\r\n0.0566\r\n\r\n\r\n0.0641\r\n\r\n\r\n0.0603\r\n\r\n\r\n0.0563\r\n\r\n\r\n0.0476\r\n\r\n\r\n0.0401\r\n\r\n\r\navg_hft_buy_sell_diff\r\n\r\n\r\n-0.0317\r\n\r\n\r\n-0.0112\r\n\r\n\r\n-0.0146\r\n\r\n\r\n-0.0046\r\n\r\n\r\n0.0039\r\n\r\n\r\n0.0071\r\n\r\n\r\n0.0117\r\n\r\n\r\navg_hft_inequilibrium\r\n\r\n\r\n-0.6879\r\n\r\n\r\n-0.2948\r\n\r\n\r\n-0.2616\r\n\r\n\r\n-0.0664\r\n\r\n\r\n0.0768\r\n\r\n\r\n0.1529\r\n\r\n\r\n0.2846\r\n\r\n\r\nTabloda farklı getiri aralıklarına giren günlerin HFT\r\ndeğişkenlerinin ortalamaları bulunmaktadır. Eksi %5’ten sıfıra\r\nyaklaşırken HFT ve HFT alım değerleri küçülmekte olup, sıfırdan sonrası\r\niçin büyümektedir. HFT alım ve satım farkında oluşan ortalamalarda ise\r\nsıfıra yaklaşırken küçülüp pozitif EPM’ler durumunda ise ortalamaları\r\nbüyümektedir. HFT farkın HFT ye oranının ortalamasında ise eksi %5 altı\r\nEPM’li hisse ve günlerden itibaren pozitif EPM’li hisse-günlere doğru\r\nyaklaştıkça bu ortalama değer büyümektedir.\r\nUç Fiyat\r\nHareketli gün-hisselerde HFT Aktivitesi\r\n\r\n\r\ntable3 <- data %>% \r\n   select(hft, hft_buy, hft_sell, return) %>% \r\n  mutate(hft_buy_sell_diff = hft_buy - hft_sell,\r\n         hft_inequilibrium = (hft_buy - hft_sell)/hft, \r\n         return_type=case_when(\r\n           return <= -0.05 ~ \"below -5%\",\r\n           return > -0.05 & return <= -0.02 ~ \"between -5% and -2%\",\r\n           return > -0.02 & return <= -0.005 ~ \"between -2% and -0.5%\",\r\n           return > -0.005 & return <= 0.005 ~ \"between -0.5% and 0.5%\",\r\n           return > 0.005 & return <= 0.02 ~ \"between 0.5% and 2%\",\r\n           return > 0.02 & return <= 0.05 ~ \"between 2% and 5%\",\r\n           return > 0.05 ~ \"above 5%\"\r\n    )) %>% \r\n  group_by(return_type) %>% \r\n  summarise(\r\n    avg_hft = mean(hft),\r\n    avg_hft_buy = mean(hft_buy),\r\n    avg_hft_sell = mean(hft_sell),\r\n    avg_hft_buy_sell_diff = mean(hft_buy_sell_diff),\r\n    avg_hft_inequilibrium = mean(hft_inequilibrium, na.rm = T),\r\n    p_hft = t.test(hft)$p.value,\r\n    p_hft_buy = t.test(hft_buy)$p.value,\r\n    p_hft_sell = t.test(hft_sell)$p.value,\r\n    p_hft_buy_sell_diff = t.test(hft_buy_sell_diff)$p.value,\r\n    p_hft_inequilibrium = t.test(hft_inequilibrium)$p.value\r\n  ) %>% \r\n  mutate(\r\n    return_type = factor(\r\n      return_type, levels = c(\"below -5%\",\r\n                              \"between -5% and -2%\",\r\n                              \"between -2% and -0.5%\",\r\n                              \"between -0.5% and 0.5%\",\r\n                              \"between 0.5% and 2%\",\r\n                              \"between 2% and 5%\",\r\n                              \"above 5%\")\r\n    )\r\n  ) %>% \r\n  arrange(return_type) %>% \r\n  select(return_type, avg_hft, p_hft, avg_hft_buy, p_hft_buy, avg_hft_sell,\r\n         p_hft_sell, avg_hft_buy_sell_diff, p_hft_buy_sell_diff, avg_hft_inequilibrium, p_hft_inequilibrium) %>% \r\n  mutate_at(vars(-c(return_type)), .funs = function(x) round(x, digits = 4)) %>% \r\n  mutate_if(is.character, as.numeric) %>% \r\n  t() %>% \r\n  as.data.frame() %>% \r\n  `colnames<-`(.[1,]) %>% \r\n  slice(-1) %>% \r\n  mutate_if(is.character, as.numeric) %>% \r\n  mutate_all(.funs = function(x) x - .[,4])\r\n  \r\nkable(table3) %>% \r\n  kable_paper(\"hover\", full_width = F)\r\n\r\n\r\n\r\n\r\n\r\nbelow -5%\r\n\r\n\r\nbetween -5% and -2%\r\n\r\n\r\nbetween -2% and -0.5%\r\n\r\n\r\nbetween -0.5% and 0.5%\r\n\r\n\r\nbetween 0.5% and 2%\r\n\r\n\r\nbetween 2% and 5%\r\n\r\n\r\nabove 5%\r\n\r\n\r\navg_hft\r\n\r\n\r\n-0.0108\r\n\r\n\r\n-0.0078\r\n\r\n\r\n-0.0013\r\n\r\n\r\n0\r\n\r\n\r\n0.0001\r\n\r\n\r\n-0.0074\r\n\r\n\r\n-0.0122\r\n\r\n\r\np_hft\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\navg_hft_buy\r\n\r\n\r\n-0.0221\r\n\r\n\r\n-0.0103\r\n\r\n\r\n-0.0062\r\n\r\n\r\n0\r\n\r\n\r\n0.0045\r\n\r\n\r\n-0.0010\r\n\r\n\r\n-0.0039\r\n\r\n\r\np_hft_buy\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\navg_hft_sell\r\n\r\n\r\n0.0050\r\n\r\n\r\n-0.0037\r\n\r\n\r\n0.0038\r\n\r\n\r\n0\r\n\r\n\r\n-0.0040\r\n\r\n\r\n-0.0127\r\n\r\n\r\n-0.0202\r\n\r\n\r\np_hft_sell\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\n0.0000\r\n\r\n\r\navg_hft_buy_sell_diff\r\n\r\n\r\n-0.0271\r\n\r\n\r\n-0.0066\r\n\r\n\r\n-0.0100\r\n\r\n\r\n0\r\n\r\n\r\n0.0085\r\n\r\n\r\n0.0117\r\n\r\n\r\n0.0163\r\n\r\n\r\np_hft_buy_sell_diff\r\n\r\n\r\n-0.0020\r\n\r\n\r\n-0.0020\r\n\r\n\r\n-0.0020\r\n\r\n\r\n0\r\n\r\n\r\n0.0034\r\n\r\n\r\n-0.0019\r\n\r\n\r\n0.0097\r\n\r\n\r\navg_hft_inequilibrium\r\n\r\n\r\n-0.6215\r\n\r\n\r\n-0.2284\r\n\r\n\r\n-0.1952\r\n\r\n\r\n0\r\n\r\n\r\n0.1432\r\n\r\n\r\n0.2193\r\n\r\n\r\n0.3510\r\n\r\n\r\np_hft_inequilibrium\r\n\r\n\r\n-0.0005\r\n\r\n\r\n-0.0005\r\n\r\n\r\n-0.0005\r\n\r\n\r\n0\r\n\r\n\r\n-0.0005\r\n\r\n\r\n-0.0005\r\n\r\n\r\n0.0004\r\n\r\n\r\nTablo HFT aktivitesinin negatif uç fiyat hareketleri sırasında\r\nalım yönlü pozisyon almayı azalttığını, pozitif uç fiyat hareketleri\r\nsırasında ise satım yönlü pozisyon almayı düşürdüğünü\r\ngöstermektedir.\r\nIt was 0 (zero) because the p values were too small.\r\nUç\r\nfiyat hareketleri ve HFT ilişkisi – Regresyon modelleri\r\n\\(HFT_{i,t}= EPM_{i,t}^{+0.05} +\r\nEPM_{i,t}^{-0.05} + \\epsilon_{i,t}\\)\r\n\\(HFT_{i,t}= EPM_{i,t}^{+0.02} +\r\nEPM_{i,t}^{-0.02} + \\epsilon_{i,t}\\)\r\n\\(HFT_{i,t}= EPM_{i,t}^{+0.05} +\r\nEPM_{i,t}^{-0.05} + Volume_{i,t} + Liquidity_{i,t} + Volatility_{i,t} +\r\n\\epsilon_{i,t}\\)\r\n\\(HFT_{i,t}= EPM_{i,t}^{+0.02} +\r\nEPM_{i,t}^{-0.02} + Volume_{i,t} + Liquidity_{i,t} + Volatility_{i,t} +\r\n\\epsilon_{i,t}\\)\r\nToplam HFT Oranı\r\nBelirleyicileri\r\n\r\n\r\ndata_all_1 <- data %>% \r\n  select(hft, return) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft = (hft - mean(hft)) / sd(hft)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_all_1 <- lm(hft ~ `return_type_above 5%` + `return_type_below -5%`, data = data_all_1)\r\nstargazer(model_all_1, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                    hft            \r\n---------------------------------------------------\r\n`return_type_above 5%`           -0.179**          \r\n                                  (0.084)          \r\n                                                   \r\n`return_type_below -5%`           -0.154*          \r\n                                  (0.093)          \r\n                                                   \r\nConstant                           0.004           \r\n                                  (0.010)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.001           \r\nAdjusted R2                        0.001           \r\nResidual Std. Error         1.000 (df = 10167)     \r\nF Statistic               3.589** (df = 2; 10167)  \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_all_2 <- lm(hft ~ `return_type_above 2%` + `return_type_below -2%`, data = data_all_1)\r\nstargazer(model_all_2, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                    hft            \r\n---------------------------------------------------\r\n`return_type_above 2%`           -0.115***         \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`          -0.123***         \r\n                                  (0.034)          \r\n                                                   \r\nConstant                          0.025**          \r\n                                  (0.011)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.002           \r\nAdjusted R2                        0.002           \r\nResidual Std. Error         0.999 (df = 10167)     \r\nF Statistic              12.039*** (df = 2; 10167) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\ndata_all_2 <- data %>% \r\n  select(hft, return, volume, liquidity, volatility) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft = (hft - mean(hft)) / sd(hft),\r\n         volume = (volume - mean(volume)) / sd(volume),\r\n         liquidity =(liquidity - mean(liquidity)) / sd(liquidity)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_all_3 <- lm(hft ~ `return_type_above 5%` + `return_type_below -5%` +\r\n                    volume + liquidity + volatility, data = data_all_2)\r\nstargazer(model_all_3, type = \"text\") \r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                    hft            \r\n---------------------------------------------------\r\n`return_type_above 5%`            0.159*           \r\n                                  (0.088)          \r\n                                                   \r\n`return_type_below -5%`           0.230**          \r\n                                  (0.098)          \r\n                                                   \r\nvolume                           -0.246***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                         -0.001           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -3.811***         \r\n                                  (0.687)          \r\n                                                   \r\nConstant                         0.096***          \r\n                                  (0.020)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.067           \r\nAdjusted R2                        0.067           \r\nResidual Std. Error         0.966 (df = 10164)     \r\nF Statistic             146.079*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_all_4 <- lm(hft ~ `return_type_above 2%` + `return_type_below -2%` + \r\n                    volume + liquidity + volatility, data = data_all_2)\r\nstargazer(model_all_4, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                    hft            \r\n---------------------------------------------------\r\n`return_type_above 2%`            -0.040           \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`           -0.029           \r\n                                  (0.034)          \r\n                                                   \r\nvolume                           -0.245***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                         -0.001           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -2.594***         \r\n                                  (0.624)          \r\n                                                   \r\nConstant                         0.076***          \r\n                                  (0.018)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.067           \r\nAdjusted R2                        0.066           \r\nResidual Std. Error         0.966 (df = 10164)     \r\nF Statistic             144.902*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nAlım tarafı HFT Oranı\r\nBelirleyicileri\r\n\r\n\r\ndata_buy_1 <- data %>% \r\n  select(hft_buy, return) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft_buy = (hft_buy - mean(hft_buy)) / sd(hft_buy)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_buy_1 <- lm(hft_buy ~ `return_type_above 5%` + `return_type_below -5%`, data = data_buy_1)\r\nstargazer(model_buy_1, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                  hft_buy          \r\n---------------------------------------------------\r\n`return_type_above 5%`            -0.037           \r\n                                  (0.084)          \r\n                                                   \r\n`return_type_below -5%`          -0.336***         \r\n                                  (0.093)          \r\n                                                   \r\nConstant                           0.004           \r\n                                  (0.010)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.001           \r\nAdjusted R2                        0.001           \r\nResidual Std. Error         0.999 (df = 10167)     \r\nF Statistic              6.599*** (df = 2; 10167)  \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_buy_2 <- lm(hft_buy ~ `return_type_above 2%` + `return_type_below -2%`, data = data_buy_1)\r\nstargazer(model_buy_2, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                  hft_buy          \r\n---------------------------------------------------\r\n`return_type_above 2%`            -0.001           \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`          -0.153***         \r\n                                  (0.034)          \r\n                                                   \r\nConstant                           0.015           \r\n                                  (0.011)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.002           \r\nAdjusted R2                        0.002           \r\nResidual Std. Error         0.999 (df = 10167)     \r\nF Statistic              10.261*** (df = 2; 10167) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\ndata_buy_2 <- data %>% \r\n  select(hft_buy, return, volume, liquidity, volatility) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft_buy = (hft_buy - mean(hft_buy)) / sd(hft_buy),\r\n         volume = (volume - mean(volume)) / sd(volume),\r\n         liquidity =(liquidity - mean(liquidity)) / sd(liquidity)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_buy_3 <- lm(hft_buy ~ `return_type_above 5%` + `return_type_below -5%` \r\n                  + volume + liquidity + volatility, data = data_buy_2)\r\nstargazer(model_buy_3, type = \"text\") \r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                  hft_buy          \r\n---------------------------------------------------\r\n`return_type_above 5%`           0.256***          \r\n                                  (0.089)          \r\n                                                   \r\n`return_type_below -5%`           -0.004           \r\n                                  (0.099)          \r\n                                                   \r\nvolume                           -0.209***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                         0.0004           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -3.339***         \r\n                                  (0.693)          \r\n                                                   \r\nConstant                         0.085***          \r\n                                  (0.020)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.049           \r\nAdjusted R2                        0.049           \r\nResidual Std. Error         0.975 (df = 10164)     \r\nF Statistic             105.283*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_buy_4 <- lm(hft_buy ~ `return_type_above 2%` + `return_type_below -2%` \r\n                  + volume + liquidity + volatility, data = data_buy_2)\r\nstargazer(model_buy_4, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                  hft_buy          \r\n---------------------------------------------------\r\n`return_type_above 2%`            0.069**          \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`           -0.066*          \r\n                                  (0.035)          \r\n                                                   \r\nvolume                           -0.209***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                          0.001           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -2.658***         \r\n                                  (0.630)          \r\n                                                   \r\nConstant                         0.068***          \r\n                                  (0.019)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.049           \r\nAdjusted R2                        0.049           \r\nResidual Std. Error         0.975 (df = 10164)     \r\nF Statistic             105.651*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nSatım Tarafı HFT Oranı\r\nBelirleyicileri\r\n\r\n\r\ndata_sell_1 <- data %>% \r\n  select(hft_sell, return) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft_sell = (hft_sell - mean(hft_sell)) / sd(hft_sell)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_sell_1 <- lm(hft_sell ~ `return_type_above 5%` + `return_type_below -5%`, data = data_sell_1)\r\nstargazer(model_sell_1, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                 hft_sell          \r\n---------------------------------------------------\r\n`return_type_above 5%`           -0.278***         \r\n                                  (0.084)          \r\n                                                   \r\n`return_type_below -5%`            0.106           \r\n                                  (0.093)          \r\n                                                   \r\nConstant                           0.003           \r\n                                  (0.010)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.001           \r\nAdjusted R2                        0.001           \r\nResidual Std. Error         0.999 (df = 10167)     \r\nF Statistic              6.165*** (df = 2; 10167)  \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_sell_2 <- lm(hft_sell ~ `return_type_above 2%` + `return_type_below -2%`, data = data_sell_1)\r\nstargazer(model_sell_2, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                 hft_sell          \r\n---------------------------------------------------\r\n`return_type_above 2%`           -0.189***         \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`           -0.052           \r\n                                  (0.034)          \r\n                                                   \r\nConstant                          0.027**          \r\n                                  (0.011)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.004           \r\nAdjusted R2                        0.004           \r\nResidual Std. Error         0.998 (df = 10167)     \r\nF Statistic              19.030*** (df = 2; 10167) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\ndata_sell_2 <- data %>% \r\n  select(hft_sell, return, volume, liquidity, volatility) %>% \r\n  mutate(\r\n    return_type=case_when(\r\n      return <= -0.05 ~ \"below -5%\",\r\n      return > 0.05 ~ \"above 5%\",\r\n      return <= -0.02 ~ \"below -2%\",\r\n      return > 0.02 ~ \"above 2%\"\r\n    )\r\n  ) %>% \r\n  mutate(hft_sell = (hft_sell - mean(hft_sell)) / sd(hft_sell),\r\n         volume = (volume - mean(volume)) / sd(volume),\r\n         liquidity =(liquidity - mean(liquidity)) / sd(liquidity)) %>% \r\n  fastDummies::dummy_cols(.) %>% \r\n  mutate_if(is.numeric, ~replace_na(., 0))\r\n\r\nmodel_sell_3 <- lm(hft_sell ~ `return_type_above 5%` + `return_type_below -5%` + \r\n                     volume + liquidity + volatility, data = data_sell_2)\r\nstargazer(model_sell_3, type = \"text\") \r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                 hft_sell          \r\n---------------------------------------------------\r\n`return_type_above 5%`            -0.020           \r\n                                  (0.089)          \r\n                                                   \r\n`return_type_below -5%`          0.397***          \r\n                                  (0.099)          \r\n                                                   \r\nvolume                           -0.222***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                          0.007           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                       -2.537***         \r\n                                  (0.693)          \r\n                                                   \r\nConstant                         0.063***          \r\n                                  (0.020)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.051           \r\nAdjusted R2                        0.051           \r\nResidual Std. Error         0.974 (df = 10164)     \r\nF Statistic             109.717*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nmodel_sell_4 <- lm(hft_sell ~ `return_type_above 2%` + `return_type_below -2%` + \r\n                     volume + liquidity + volatility, data = data_sell_2)\r\nstargazer(model_sell_4, type = \"text\")\r\n\r\n\r\n\r\n===================================================\r\n                            Dependent variable:    \r\n                        ---------------------------\r\n                                 hft_sell          \r\n---------------------------------------------------\r\n`return_type_above 2%`           -0.134***         \r\n                                  (0.031)          \r\n                                                   \r\n`return_type_below -2%`            0.016           \r\n                                  (0.035)          \r\n                                                   \r\nvolume                           -0.222***         \r\n                                  (0.014)          \r\n                                                   \r\nliquidity                          0.008           \r\n                                  (0.014)          \r\n                                                   \r\nvolatility                        -1.232*          \r\n                                  (0.629)          \r\n                                                   \r\nConstant                          0.047**          \r\n                                  (0.019)          \r\n                                                   \r\n---------------------------------------------------\r\nObservations                      10,170           \r\nR2                                 0.052           \r\nAdjusted R2                        0.051           \r\nResidual Std. Error         0.974 (df = 10164)     \r\nF Statistic             110.402*** (df = 5; 10164) \r\n===================================================\r\nNote:                   *p<0.1; **p<0.05; ***p<0.01\r\n\r\nSonuç olarak;\r\nHisse senetlerinde ve aşırı fiyat hareketlerinin olduğu günlerde daha\r\ndüşük HFT aktivitesi gözlemlenmiştir.\r\nPozitif aşırı fiyat hareketleri sırasında satış tarafında HFT\r\nazalmıştır.\r\nNegatif aşırı fiyat hareketleri sırasında HFT alış tarafında\r\nazalmıştır.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-08-hft-tr/hft-tr_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2022-05-08T23:37:00+03:00",
    "input_file": {}
  }
]
